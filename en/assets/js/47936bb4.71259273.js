"use strict";(self.webpackChunkutm_doc=self.webpackChunkutm_doc||[]).push([[4254],{3685:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"Algorithm_Development/SLAM/VINS-Fusion/VINS-Fusion","title":"VINS-Fusion ","description":"Sources//github.com/HKUST-Aerial-Robotics/VINS-Fusion https://github.com/JanekDev/VINS-Fusion-ROS2-humble-arm","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/09_Algorithm_Development/04_SLAM/VINS-Fusion/VINS-Fusion.md","sourceDirName":"09_Algorithm_Development/04_SLAM/VINS-Fusion","slug":"/Algorithm_Development/SLAM/VINS-Fusion/","permalink":"/en/Algorithm_Development/SLAM/VINS-Fusion/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"VINS-Fusion ","source":"https://wiki.utmsys.org/Algorithm_Development/SLAM/VINS-Fusion/"},"sidebar":"tutorialSidebar","previous":{"title":"RTAB-MAP ","permalink":"/en/Algorithm_Development/SLAM/RTAB-MAP/"},"next":{"title":"9.5 \u4eff\u771f\u6a21\u62df\u5668","permalink":"/en/05_SIMULATOR"}}');var o=i(4848),r=i(8453);const t={title:"VINS-Fusion ",source:"https://wiki.utmsys.org/Algorithm_Development/SLAM/VINS-Fusion/"},a=void 0,l={},c=[{value:"ROS2 Humble version of VINS-Fusion, suitable for",id:"ros2-humble-version-of-vins-fusion-suitable-for",level:2},{value:"Notice",id:"notice",level:3},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Construction",id:"construction",level:3},{value:"Play EuRoC dataset",id:"play-euroc-dataset",level:3},{value:"Original Readme file",id:"original-readme-file",level:2},{value:"VINS Fusion",id:"vins-fusion",level:2},{value:"Optimization-based multi-sensor state",id:"optimization-based-multi-sensor-state",level:2},{value:"1.",id:"1",level:2},{value:"1.1 Ubuntu and",id:"11-ubuntu-and",level:3},{value:"1.2. Ceres",id:"12-ceres",level:3},{value:"2. Building VINS-",id:"2-building-vins-",level:2},{value:"3. EuRoC",id:"3-euroc",level:2},{value:"3.1 Monocular Camera +",id:"31-monocular-camera-",level:3},{value:"3.2 Stereo Camera +",id:"32-stereo-camera-",level:3},{value:"3.3 Stereo",id:"33-stereo",level:3},{value:"4. KITTI",id:"4-kitti",level:2},{value:"4.1 KITTI Odometry (Stereo",id:"41-kitti-odometry-stereo",level:3},{value:"4.2 KITTI GPS Fusion (Stereo+GPS",id:"42-kitti-gps-fusion-stereogps",level:3},{value:"5. VINS-Fusion In-Vehicle",id:"5-vins-fusion-in-vehicle",level:2},{value:"6.",id:"6",level:2},{value:"6.1 Configuration",id:"61-configuration",level:3},{value:"6.2 Camera",id:"62-camera",level:3},{value:"7. Docker",id:"7-docker",level:2},{value:"8.",id:"8",level:2},{value:"9.",id:"9",level:2}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(n.p,{children:["Sources: ",(0,o.jsx)(n.a,{href:"https://github.com/HKUST-Aerial-Robotics/VINS-Fusion",children:"https://github.com/HKUST-Aerial-Robotics/VINS-Fusion"})," ",(0,o.jsx)(n.a,{href:"https://github.com/JanekDev/VINS-Fusion-ROS2-humble-arm",children:"https://github.com/JanekDev/VINS-Fusion-ROS2-humble-arm"})]}),"\n",(0,o.jsx)(n.h2,{id:"ros2-humble-version-of-vins-fusion-suitable-for",children:"ROS2 Humble version of VINS-Fusion, suitable for"}),"\n",(0,o.jsx)(n.h3,{id:"notice",children:"Notice"}),"\n",(0,o.jsx)(n.p,{children:"You can now run VINS-Fusion on ROS2 Humble using ros2 launch or ros2 run."}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://github.com/zinuok/VINS-Fusion-ROS2",children:"The code is mostly based on this repository"})," by zinuok ."]}),"\n",(0,o.jsxs)(n.blockquote,{children:["\n",(0,o.jsx)(n.p,{children:"Will be removed (to make the package smaller):"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["GPU enable/disable functionality has also been added: see ",(0,o.jsx)(n.a,{href:"https://github.com/zinuok/VINS-Fusion-ROS2/blob/main/config/euroc/euroc_stereo_imu_config.yaml#L19-L21",children:"EuRoC configuration"})," (references ",(0,o.jsx)(n.a,{href:"https://github.com/pjrambo/VINS-Fusion-gpu",children:"here"})," and ",(0,o.jsx)(n.a,{href:"https://github.com/pjrambo/VINS-Fusion-gpu/issues/33#issuecomment-1097642597",children:"here"})," )"]}),"\n",(0,o.jsxs)(n.li,{children:["The GPU version has some CUDA library ",(0,o.jsx)(n.a,{href:"https://github.com/zinuok/VINS-Fusion-ROS2/blob/main/vins/src/featureTracker/feature_tracker.h#L21-L23",children:"dependencies: OpenCV with CUDA"}),". So if you don't mind and only need the CPU version, comment out the following compiler macros on line 14 of the 'feature_tracker.h' file:"]}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-c",children:"#define GPU_MODE 1\n"})}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"system"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Ubuntu 20.04"}),"\n",(0,o.jsx)(n.li,{children:"ROS2 humble"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Dependent Libraries"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"OpenCV & cv_bridge for ROS2 Humble"}),"\n",(0,o.jsx)(n.li,{children:"Ceres Solver-2.1.0"}),"\n",(0,o.jsx)(n.li,{children:"Own-3.3.9"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"construction",children:"Construction"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"install_external_deps.sh"})," Install dependencies by running the script (OpenCV, Ceres, Eigen will be installed)"]}),"\n",(0,o.jsx)(n.li,{children:"Build the package using colcon build"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"colcon build --symlink-install\n"})}),"\n",(0,o.jsx)(n.h3,{id:"play-euroc-dataset",children:"Play EuRoC dataset"}),"\n",(0,o.jsxs)(n.p,{children:["To download the sample EuRoC dataset package, run ",(0,o.jsx)(n.code,{children:"get_example_data.sh"})," the script. Then use the script to convert the dataset package to ROS2 format ",(0,o.jsx)(n.code,{children:"rosbags-convert"}),"."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"./get_example_data.sh\nrosbags-convert data/V1_02_medium.bag --dst /output/path\n"})}),"\n",(0,o.jsxs)(n.p,{children:["If you don't have ",(0,o.jsx)(n.code,{children:"rosbags-convert"})," the script, you can install it using the command ",(0,o.jsx)(n.code,{children:"pip install rosbags"}),". Then, you can ",(0,o.jsx)(n.code,{children:"ros2 bag play"})," play the package using standard commands:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"ros2 bag play /data/V1_02_medium\n"})}),"\n",(0,o.jsx)(n.h2,{id:"original-readme-file",children:"Original Readme file"}),"\n",(0,o.jsx)(n.h2,{id:"vins-fusion",children:"VINS Fusion"}),"\n",(0,o.jsx)(n.h2,{id:"optimization-based-multi-sensor-state",children:"Optimization-based multi-sensor state"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://github.com/HKUST-Aerial-Robotics/VINS-Fusion/blob/master/support_files/image/vins_logo.png",children:(0,o.jsx)(n.img,{src:"https://github.com/HKUST-Aerial-Robotics/VINS-Fusion/raw/master/support_files/image/vins_logo.png",alt:""})})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://github.com/HKUST-Aerial-Robotics/VINS-Fusion/blob/master/support_files/image/kitti.png",children:(0,o.jsx)(n.img,{src:"https://github.com/HKUST-Aerial-Robotics/VINS-Fusion/raw/master/support_files/image/kitti.png",alt:""})})}),"\n",(0,o.jsxs)(n.p,{children:["VINS-Fusion is an optimization-based multi-sensor state estimator that enables accurate self-localization for autonomous applications (drones, cars, and AR/VR). VINS-Fusion is an extension of ",(0,o.jsx)(n.a,{href:"https://github.com/HKUST-Aerial-Robotics/VINS-Mono",children:"VINS-Mono"})," that supports multiple visual-inertial sensor types (monocular camera + IMU, stereo camera + IMU, or even just stereo camera). We also show an example fusing VINS with GPS. ",(0,o.jsx)(n.strong,{children:"Features:"})]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Supports multiple sensors (stereo camera/monocular camera + IMU/stereo camera + IMU)"}),"\n",(0,o.jsx)(n.li,{children:"Online spatial calibration (conversion between camera and IMU)"}),"\n",(0,o.jsx)(n.li,{children:"Online time calibration (time offset between camera and IMU)"}),"\n",(0,o.jsx)(n.li,{children:"Visual loop closure"}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["We are ",(0,o.jsx)(n.strong,{children:"the top"})," open source stereo algorithm on ",(0,o.jsx)(n.a,{href:"http://www.cvlibs.net/datasets/kitti/eval_odometry.php",children:"the KITTI odometry benchmark"})," (January 12, 2019)."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Authors:"})," ",(0,o.jsx)(n.a,{href:"http://www.qintonguav.com/",children:"Qin Tong"}),", Cao Shaozu, Pan Jie, ",(0,o.jsx)(n.a,{href:"https://peiliangli.github.io/",children:"Li Peiliang"}),", and ",(0,o.jsx)(n.a,{href:"http://www.ece.ust.hk/ece.php/profile/facultydetail/eeshaojie",children:"Shen Shaojie"})," from the Aerial ",(0,o.jsx)(n.a,{href:"http://uav.ust.hk/",children:"Robotics Group"})," ",(0,o.jsx)(n.a,{href:"https://www.ust.hk/",children:"of the Hong Kong University of Science and Technology"})]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"video:"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://www.youtube.com/embed/1qye82aW7nI",children:(0,o.jsx)(n.img,{src:"https://camo.githubusercontent.com/16dab50d43d72344cae8393f938211fc433c1aa17d1fb3d13835ef41f67d6b47/687474703a2f2f696d672e796f75747562652e636f6d2f76692f3171796538326157376e492f302e6a7067",alt:"Wiens"})})}),"\n",(0,o.jsx)(n.p,{children:"**Related Papers: **(**The paper and code are not exactly the same)"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Online Temporal Calibration of Monocular Visual-Inertial Systems"}),", Tong Qin, Shaojie Shen, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS, 2018), ",(0,o.jsx)(n.strong,{children:"Best Student Paper Award"})," ",(0,o.jsx)(n.a,{href:"https://ieeexplore.ieee.org/abstract/document/8593603",children:"pdf"})]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"VINS-Mono: A Robust and Versatile Monocular Visual-Inertial State Estimator"}),", Tong Qin, Peiliang Li, Shaojie Shen, IEEE Transactions on Robotics"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["If you use VINS-Fusion for academic research, please cite our related papers ",(0,o.jsx)(n.a,{href:"https://github.com/HKUST-Aerial-Robotics/VINS-Fusion/blob/master/support_files/paper_bib.txt",children:"."})]})}),"\n",(0,o.jsx)(n.h2,{id:"1",children:"1."}),"\n",(0,o.jsx)(n.h3,{id:"11-ubuntu-and",children:"1.1 Ubuntu and"}),"\n",(0,o.jsxs)(n.p,{children:["Ubuntu 64-bit 16.04 or 18.04. ROS Kinetic or Melodic. ROS ",(0,o.jsx)(n.a,{href:"http://wiki.ros.org/ROS/Installation",children:"installation"})]}),"\n",(0,o.jsx)(n.h3,{id:"12-ceres",children:"1.2. Ceres"}),"\n",(0,o.jsxs)(n.p,{children:["Follow ",(0,o.jsx)(n.a,{href:"http://ceres-solver.org/installation.html",children:"the Ceres installation"}),"."]}),"\n",(0,o.jsx)(n.h2,{id:"2-building-vins-",children:"2. Building VINS-"}),"\n",(0,o.jsx)(n.p,{children:"Clone the repository and catkin_make:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",children:"cd ~/catkin_ws/src\n    git clone https://github.com/HKUST-Aerial-Robotics/VINS-Fusion.git\n    cd ../\n    catkin_make\n    source ~/catkin_ws/devel/setup.bash\n"})}),"\n",(0,o.jsx)(n.p,{children:"(If this step fails, try finding another clean computer or reinstalling Ubuntu and ROS)"}),"\n",(0,o.jsx)(n.h2,{id:"3-euroc",children:"3. EuRoC"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"http://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets",children:"Download the EuRoC MAV dataset"})," to YOUR_DATASET_FOLDER. Using MH_01 as an example, you can run VINS-Fusion with three sensor types: monocular camera + IMU, stereo camera + IMU, and stereo camera. Open four terminals and run VINS odometry, visual loop closure (optional), rviz, and play the bag file. The green path is for VIO odometry; the red path is for odometry with visual loop closure."]}),"\n",(0,o.jsx)(n.h3,{id:"31-monocular-camera-",children:"3.1 Monocular Camera +"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",children:"roslaunch vins vins_rviz.launch\n    rosrun vins vins_node ~/catkin_ws/src/VINS-Fusion/config/euroc/euroc_mono_imu_config.yaml \n    (optional) rosrun loop_fusion loop_fusion_node ~/catkin_ws/src/VINS-Fusion/config/euroc/euroc_mono_imu_config.yaml \n    rosbag play YOUR_DATASET_FOLDER/MH_01_easy.bag\n"})}),"\n",(0,o.jsx)(n.h3,{id:"32-stereo-camera-",children:"3.2 Stereo Camera +"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",children:"roslaunch vins vins_rviz.launch\n    rosrun vins vins_node ~/catkin_ws/src/VINS-Fusion/config/euroc/euroc_stereo_imu_config.yaml \n    (optional) rosrun loop_fusion loop_fusion_node ~/catkin_ws/src/VINS-Fusion/config/euroc/euroc_stereo_imu_config.yaml \n    rosbag play YOUR_DATASET_FOLDER/MH_01_easy.bag\n"})}),"\n",(0,o.jsx)(n.h3,{id:"33-stereo",children:"3.3 Stereo"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",children:"roslaunch vins vins_rviz.launch\n    rosrun vins vins_node ~/catkin_ws/src/VINS-Fusion/config/euroc/euroc_stereo_config.yaml \n    (optional) rosrun loop_fusion loop_fusion_node ~/catkin_ws/src/VINS-Fusion/config/euroc/euroc_stereo_config.yaml \n    rosbag play YOUR_DATASET_FOLDER/MH_01_easy.bag\n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://github.com/HKUST-Aerial-Robotics/VINS-Fusion/blob/master/support_files/image/euroc.gif",children:(0,o.jsx)(n.img,{src:"https://github.com/HKUST-Aerial-Robotics/VINS-Fusion/raw/master/support_files/image/euroc.gif",alt:""})})}),"\n",(0,o.jsx)(n.h2,{id:"4-kitti",children:"4. KITTI"}),"\n",(0,o.jsx)(n.h3,{id:"41-kitti-odometry-stereo",children:"4.1 KITTI Odometry (Stereo"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"http://www.cvlibs.net/datasets/kitti/eval_odometry.php",children:"Download the KITTI odometry dataset"})," to YOUR_DATASET_FOLDER. Using sequence 00 as an example, open two terminals and run vins and rviz respectively. (We evaluated odometry on the KITTI benchmark, but did not use loop closure.)"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",children:"roslaunch vins vins_rviz.launch\n    (optional) rosrun loop_fusion loop_fusion_node ~/catkin_ws/src/VINS-Fusion/config/kitti_odom/kitti_config00-02.yaml\n    rosrun vins kitti_odom_test ~/catkin_ws/src/VINS-Fusion/config/kitti_odom/kitti_config00-02.yaml YOUR_DATASET_FOLDER/sequences/00/\n"})}),"\n",(0,o.jsx)(n.h3,{id:"42-kitti-gps-fusion-stereogps",children:"4.2 KITTI GPS Fusion (Stereo+GPS"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"http://www.cvlibs.net/datasets/kitti/raw_data.php",children:"Download the original KITTI dataset"})," to YOUR_DATASET_FOLDER. Use ",(0,o.jsx)(n.a,{href:"https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_10_03_drive_0027/2011_10_03_drive_0027_sync.zip",children:"2011_10_03_drive_0027_synced"})," as an example. Open three terminals and run vins, global fusion, and rviz, respectively. The green path represents VIO odometry; the blue path represents GPS odometry with global fusion."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",children:"roslaunch vins vins_rviz.launch\n    rosrun vins kitti_gps_test ~/catkin_ws/src/VINS-Fusion/config/kitti_raw/kitti_10_03_config.yaml YOUR_DATASET_FOLDER/2011_10_03_drive_0027_sync/ \n    rosrun global_fusion global_fusion_node\n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://github.com/HKUST-Aerial-Robotics/VINS-Fusion/blob/master/support_files/image/kitti.gif",children:(0,o.jsx)(n.img,{src:"https://github.com/HKUST-Aerial-Robotics/VINS-Fusion/raw/master/support_files/image/kitti.gif",alt:""})})}),"\n",(0,o.jsx)(n.h2,{id:"5-vins-fusion-in-vehicle",children:"5. VINS-Fusion In-Vehicle"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://drive.google.com/open?id=10t9H1u8pMGDOI6Q2w2uezEq5Ib-Z8tLz",children:"Download the car package"})," to your dataset folder. Open four terminals and run VIO odometry, visual loop closure (optional), and rviz and play the car package files. The green path is the VIO odometry; the red path is the odometry with visual loop closure."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",children:"roslaunch vins vins_rviz.launch\n    rosrun vins vins_node ~/catkin_ws/src/VINS-Fusion/config/vi_car/vi_car.yaml \n    (optional) rosrun loop_fusion loop_fusion_node ~/catkin_ws/src/VINS-Fusion/config/vi_car/vi_car.yaml \n    rosbag play YOUR_DATASET_FOLDER/car.bag\n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.a,{href:"https://github.com/HKUST-Aerial-Robotics/VINS-Fusion/blob/master/support_files/image/car_gif.gif",children:(0,o.jsx)(n.img,{src:"https://github.com/HKUST-Aerial-Robotics/VINS-Fusion/raw/master/support_files/image/car_gif.gif",alt:""})})}),"\n",(0,o.jsx)(n.h2,{id:"6",children:"6."}),"\n",(0,o.jsx)(n.p,{children:"VIO is not just a software algorithm; it relies heavily on the quality of your hardware. For beginners, we recommend using a professional device with a global shutter camera and hardware synchronization capabilities to run VIO."}),"\n",(0,o.jsx)(n.h3,{id:"61-configuration",children:"6.1 Configuration"}),"\n",(0,o.jsx)(n.p,{children:"Write a configuration file for your device. You can use the configuration files for EuRoC and KITTI as examples."}),"\n",(0,o.jsx)(n.h3,{id:"62-camera",children:"6.2 Camera"}),"\n",(0,o.jsxs)(n.p,{children:["VINS-Fusion supports multiple camera models (pinhole, MEI, equidistant). You can use ",(0,o.jsx)(n.a,{href:"https://github.com/hengli/camodocal",children:"the camera models"})," to calibrate your camera. We have placed some sample data under /camera_models/calibrationdata to guide you on how to calibrate."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",children:"cd ~/catkin_ws/src/VINS-Fusion/camera_models/camera_calib_example/\nrosrun camera_models Calibrations -w 12 -h 8 -s 80 -i calibrationdata --camera-model pinhole\n"})}),"\n",(0,o.jsx)(n.h2,{id:"7-docker",children:"7. Docker"}),"\n",(0,o.jsxs)(n.p,{children:["To further simplify the build process, we've added Docker to our code. The Docker environment acts like a sandbox, making our code independent of the environment. To run with Docker, first make sure you have ",(0,o.jsx)(n.a,{href:"http://wiki.ros.org/ROS/Installation",children:"ROS"})," and ",(0,o.jsx)(n.a,{href:"https://docs.docker.com/install/linux/docker-ce/ubuntu/",children:"Docker"})," installed on your computer. Then add your account to ",(0,o.jsx)(n.code,{children:"docker"})," the group by ",(0,o.jsx)(n.code,{children:"sudo usermod -aG docker $YOUR_USER_NAME"}),". ",(0,o.jsxs)(n.strong,{children:["Restart the terminal, or if ",(0,o.jsx)(n.code,{children:"Permission denied"})," an error"]})," occurs, log out and log back in, and enter:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",children:"cd ~/catkin_ws/src/VINS-Fusion/docker\nmake build\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Please note that the docker build process may take a while, depending on your network and machine. After VINS-Fusion is successfully built, you can use the script to run the VINS estimator ",(0,o.jsx)(n.code,{children:"run.sh"}),". The script ",(0,o.jsx)(n.code,{children:"run.sh"})," accepts multiple flags and parameters. The flags ",(0,o.jsx)(n.code,{children:"-k"})," represent KITTI, ",(0,o.jsx)(n.code,{children:"-l"})," loop fusion, ",(0,o.jsx)(n.code,{children:"-g"})," and global fusion. You can get usage details by using ",(0,o.jsx)(n.code,{children:"./run.sh -h"}),". Here are some examples of this script:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-markdown",children:"# Euroc Monocualr camera + IMU\n./run.sh ~/catkin_ws/src/VINS-Fusion/config/euroc/euroc_mono_imu_config.yaml\n\n# Euroc Stereo cameras + IMU with loop fusion\n./run.sh -l ~/catkin_ws/src/VINS-Fusion/config/euroc/euroc_mono_imu_config.yaml\n\n# KITTI Odometry (Stereo)\n./run.sh -k ~/catkin_ws/src/VINS-Fusion/config/kitti_odom/kitti_config00-02.yaml YOUR_DATASET_FOLDER/sequences/00/\n\n# KITTI Odometry (Stereo) with loop fusion\n./run.sh -kl ~/catkin_ws/src/VINS-Fusion/config/kitti_odom/kitti_config00-02.yaml YOUR_DATASET_FOLDER/sequences/00/\n\n#  KITTI GPS Fusion (Stereo + GPS)\n./run.sh -kg ~/catkin_ws/src/VINS-Fusion/config/kitti_raw/kitti_10_03_config.yaml YOUR_DATASET_FOLDER/2011_10_03_drive_0027_sync/\n"})}),"\n",(0,o.jsxs)(n.p,{children:["In the case of Euroc, you need to open another terminal and run your bag file. If you need to modify the code, just ",(0,o.jsx)(n.code,{children:"./run.sh"})," re-run it with the appropriate extension after making the changes."]}),"\n",(0,o.jsx)(n.h2,{id:"8",children:"8."}),"\n",(0,o.jsxs)(n.p,{children:["We use ",(0,o.jsx)(n.a,{href:"http://ceres-solver.org/",children:"the ceres solver"})," for nonlinear optimization, ",(0,o.jsx)(n.a,{href:"https://github.com/dorian3d/DBoW2",children:"DBoW2"})," for loop closure detection, a general ",(0,o.jsx)(n.a,{href:"https://github.com/hengli/camodocal",children:"camera model"}),", and ",(0,o.jsx)(n.a,{href:"https://geographiclib.sourceforge.io/",children:"GeographicLib"}),"."]}),"\n",(0,o.jsx)(n.h2,{id:"9",children:"9."}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"http://www.gnu.org/licenses/",children:"The source code is released under the GPLv3"})," license."]})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>a});var s=i(6540);const o={},r=s.createContext(o);function t(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:t(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);