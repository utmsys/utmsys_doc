"use strict";(self.webpackChunkutm_doc=self.webpackChunkutm_doc||[]).push([[9465],{7539:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"Algorithm_Development/HPC/ARM Perf","title":"ARM Perf","description":"Improving the performance of edge computing ARM chips requires a combination of hardware features, software optimization, and system configuration. The following is a classification of specific methods:","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/09_Algorithm_Development/08_HPC/ARM Perf.md","sourceDirName":"09_Algorithm_Development/08_HPC","slug":"/Algorithm_Development/HPC/ARM Perf","permalink":"/en/Algorithm_Development/HPC/ARM Perf","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"source":"https://wiki.utmsys.org/Algorithm_Development/HPC/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97ARM%E8%8A%AF%E7%89%87%E7%9A%84%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%9C%89%E5%93%AA%E4%BA%9B"},"sidebar":"tutorialSidebar","previous":{"title":"8xA55 ARM CPU Perf","permalink":"/en/Algorithm_Development/HPC/8xA55 ARM CPU Perf"},"next":{"title":"Arm Performance Libraries ","permalink":"/en/Algorithm_Development/HPC/Arm Performance Libraries"}}');var i=s(4848),o=s(8453);const t={source:"https://wiki.utmsys.org/Algorithm_Development/HPC/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97ARM%E8%8A%AF%E7%89%87%E7%9A%84%E6%80%A7%E8%83%BD%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95%E6%9C%89%E5%93%AA%E4%BA%9B"},a=void 0,c={},l=[{value:"1. Hardware",id:"1-hardware",level:3},{value:"2. Software and Algorithm",id:"2-software-and-algorithm",level:3},{value:"3. System and Configuration",id:"3-system-and-configuration",level:3},{value:"4.",id:"4",level:3}];function d(e){const n={code:"code",h3:"h3",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:"Improving the performance of edge computing ARM chips requires a combination of hardware features, software optimization, and system configuration. The following is a classification of specific methods:"}),"\n",(0,i.jsx)(n.h3,{id:"1-hardware",children:"1. Hardware"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Leveraging ARM architecture features"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Take full advantage of ",(0,i.jsx)(n.strong,{children:"the NEON SIMD instruction set"}),": The NEON unit of the ARM chip supports single instruction multiple data (SIMD) operations. By writing NEON-optimized code (such as using intrinsic functions or assembly), audio, video, image and other data can be processed in parallel to improve computing throughput."]}),"\n",(0,i.jsxs)(n.li,{children:["Enable ",(0,i.jsx)(n.strong,{children:"big.LITTLE architecture scheduling"}),": Some ARM chips use a heterogeneous core design (for example, large cores are responsible for high-performance tasks, and small cores handle lightweight tasks). The system scheduler (such as Linux ",(0,i.jsx)(n.code,{children:"schedutil"}),") reasonably allocates tasks to corresponding cores to avoid resource waste."]}),"\n",(0,i.jsxs)(n.li,{children:["Configure ",(0,i.jsx)(n.strong,{children:"cache policy"}),": Optimize the use of L1/L2/L3 cache, for example, by adjusting the data block size to reduce cache misses, or using prefetch instructions (such as ",(0,i.jsx)(n.code,{children:"PLD"}),") to load data into the cache in advance."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Hardware acceleration unit (accelerator)"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Call ",(0,i.jsx)(n.strong,{children:"dedicated coprocessors"}),": such as ARM's ",(0,i.jsx)(n.strong,{children:"Mali GPU"})," (for graphics rendering and general computing GPGPU), ",(0,i.jsx)(n.strong,{children:"BPU (neural network processing unit)"})," (such as Horizon J5, Rockchip RK3588 NPU), through the corresponding SDK (such as OpenCL, OpenVX) to offload deep learning, image processing and other tasks to the accelerator, reducing the CPU burden."]}),"\n",(0,i.jsxs)(n.li,{children:["Expand ",(0,i.jsx)(n.strong,{children:"external hardware"}),": Connect accelerator cards such as FPGA and ASIC through PCIe, USB, or dedicated interfaces to handle specific compute-intensive tasks (such as real-time video encoding, encryption and decryption)."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"2-software-and-algorithm",children:"2. Software and Algorithm"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Compiler and toolchain optimization"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Use ",(0,i.jsx)(n.strong,{children:"an ARM-specific compiler"}),": such as ",(0,i.jsx)(n.code,{children:"armclang"})," (ARM official compiler) or ",(0,i.jsx)(n.code,{children:"GCC"})," the ARM architecture optimization option ( ",(0,i.jsx)(n.code,{children:"-march=armv8-a+neon"}),", ",(0,i.jsx)(n.code,{children:"-O3"}),") to generate more efficient machine code."]}),"\n",(0,i.jsxs)(n.li,{children:["Enable ",(0,i.jsx)(n.strong,{children:"Link-Time Optimization (LTO)"}),": Use ",(0,i.jsx)(n.code,{children:"-flto"})," options to let the compiler optimize code across files during the link phase to reduce redundant operations."]}),"\n",(0,i.jsxs)(n.li,{children:["Take advantage of ",(0,i.jsx)(n.strong,{children:"automatic vectorization"}),": Add options during compilation ",(0,i.jsx)(n.code,{children:"-ftree-vectorize"})," to let the compiler automatically convert loops into NEON SIMD instructions (make sure the code meets the vectorization conditions, such as continuous array access and fixed number of loops)."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Algorithm and code optimization"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Data locality"}),": Reduce cross-core/cross-cache data transfers by placing frequently accessed data in the local cache of the same core (such as using ",(0,i.jsx)(n.code,{children:"__thread"})," thread local storage)."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Parallel processing"}),": Implement multi-threaded parallelism based on OpenMP, Pthreads, or C++11 thread libraries, and take advantage of ARM multi-core advantages (such as the 8-core A55 can split tasks for parallel execution)."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Lightweight algorithms"}),": To address resource constraints in edge scenarios, choose low-complexity algorithms (such as using MobileNet instead of ResNet for image classification, and using FFT instead of direct convolution for signal processing)."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"High Performance Computing Libraries"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Integrated ",(0,i.jsx)(n.strong,{children:"ARM optimization library"}),": as mentioned above ",(0,i.jsx)(n.code,{children:"Arm Performance Libraries"})," (optimized BLAS, LAPACK, FFT and other mathematical operations), ",(0,i.jsx)(n.code,{children:"Ne10"})," (NEON accelerated signal/image processing library), to avoid repeated development of low-level optimization code."]}),"\n",(0,i.jsxs)(n.li,{children:["Adapt ",(0,i.jsx)(n.strong,{children:"deep learning frameworks"}),": Use frameworks optimized for ARM (such as TensorFlow Lite for ARM and ONNX Runtime with NEON acceleration), and reduce model computational complexity through quantization (such as INT8/FP16)."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"3-system-and-configuration",children:"3. System and Configuration"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Operating system tuning"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Choose ",(0,i.jsx)(n.strong,{children:"a lightweight system"}),", such as a tailored Linux (Yocto, Buildroot) or a real-time operating system (RTOS, such as FreeRTOS, Zephyr), to reduce system resource usage and task scheduling latency."]}),"\n",(0,i.jsxs)(n.li,{children:["Optimize ",(0,i.jsx)(n.strong,{children:"CPU frequency and power consumption"}),": Use ",(0,i.jsx)(n.code,{children:"cpufreq"})," tools to adjust the core frequency to performance mode (such as ",(0,i.jsx)(n.code,{children:"performance"})," governor) to avoid frequency reduction caused by energy-saving strategies (which require a balance between power consumption and heat generation)."]}),"\n",(0,i.jsxs)(n.li,{children:["Shut down ",(0,i.jsx)(n.strong,{children:"unnecessary processes and services"}),": Disable redundant background processes (such as log services and network services) on edge devices to free up CPU and memory resources."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Memory and storage optimization"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Use ",(0,i.jsx)(n.strong,{children:"HugePages"}),": Reduce memory page table switching overhead and improve access speed to large blocks of continuous memory (suitable for scenarios such as image processing and video frame caching)."]}),"\n",(0,i.jsxs)(n.li,{children:["Use ",(0,i.jsx)(n.strong,{children:"high-speed storage"}),": Store frequently accessed data (such as model weights and intermediate results) in eMMC, NVMe, or high-speed SD cards to reduce I/O latency."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"4",children:"4."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Deep Learning Inference"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Use model compression tools (such as TensorFlow Lite Converter and ONNX Simplifier) to reduce model size, and combine them with ARM NPU SDKs (such as Horizon ",(0,i.jsx)(n.code,{children:"Horizon OpenExplorer"})," and Rockchip ",(0,i.jsx)(n.code,{children:"RKNN Toolkit"}),") for model quantization and deployment to fully utilize hardware acceleration."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Real-time data processing"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["It uses ",(0,i.jsx)(n.strong,{children:"zero-copy technology"})," (such as Linux's ",(0,i.jsx)(n.code,{children:"mmap"})," DMA direct memory access) to reduce the copy overhead of data between user state and kernel state, and is suitable for real-time processing of sensor data streams (such as cameras and radars)."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Network transmission optimization"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Enable ",(0,i.jsx)(n.strong,{children:"hardware-accelerated network protocols"})," (such as ARM's ",(0,i.jsx)(n.code,{children:"Networking Acceleration"})," engine), or bypass the kernel protocol stack through DPDK (Data Plane Development Kit) to improve network packet processing efficiency."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"By combining the above methods, the computing performance of edge computing ARM chips can be maximized within the resource limitations (such as power consumption and volume) of the chip, meeting the needs of scenarios such as real-time reasoning and data processing."})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>a});var r=s(6540);const i={},o=r.createContext(i);function t(e){const n=r.useContext(o);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),r.createElement(o.Provider,{value:n},e.children)}}}]);