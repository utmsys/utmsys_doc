"use strict";(self.webpackChunkutm_doc=self.webpackChunkutm_doc||[]).push([[7546],{4830:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>p,frontMatter:()=>a,metadata:()=>n,toc:()=>m});const n=JSON.parse('{"id":"Algorithm_Development/LLM/VLM","title":"VLM ","description":"CLIP is a multimodal machine learning model proposed by OpenAI. By performing comparative learning on large-scale image and text pairs, the model can simultaneously process images and text, mapping them into a shared vector space. This example demonstrates using CLIP for image management and text search on the RDK platform.","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/09_Algorithm_Development/07_LLM/VLM.md","sourceDirName":"09_Algorithm_Development/07_LLM","slug":"/Algorithm_Development/LLM/VLM","permalink":"/en/Algorithm_Development/LLM/VLM","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"VLM ","source":"https://wiki.utmsys.org/Algorithm_Development/LLM/VLM%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E5%9B%BE%E6%96%87%E6%A8%A1%E5%9E%8B"},"sidebar":"tutorialSidebar","previous":{"title":"9.7 \u89c6\u89c9\u8bed\u8a00\u6a21\u578b","permalink":"/en/07_VLM"},"next":{"title":"9.8 \u9ad8\u6027\u80fd\u8ba1\u7b97","permalink":"/en/08_HPC"}}');var r=o(4848),i=o(8453);const a={title:"VLM ",source:"https://wiki.utmsys.org/Algorithm_Development/LLM/VLM%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E5%9B%BE%E6%96%87%E6%A8%A1%E5%9E%8B"},s=void 0,c={},m=[{value:"More information",id:"more-information",level:2}];function l(e){const t={a:"a",h2:"h2",p:"p",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.a,{href:"https://github.com/openai/CLIP/",children:"CLIP"})," is a multimodal machine learning model proposed by OpenAI. By performing comparative learning on large-scale image and text pairs, the model can simultaneously process images and text, mapping them into a shared vector space. This example demonstrates using CLIP for image management and text search on the RDK platform."]}),"\n",(0,r.jsxs)(t.p,{children:["Code repository: ( ",(0,r.jsx)(t.a,{href:"https://github.com/D-Robotics/hobot_clip.git",children:"https://github.com/D-Robotics/hobot_clip.git"})," )"]}),"\n",(0,r.jsx)(t.p,{children:"Application scenarios: Use the CLIP image feature extractor to manage images, perform image-text search, and image-based search."}),"\n",(0,r.jsx)(t.h2,{id:"more-information",children:"More information"}),"\n",(0,r.jsxs)(t.p,{children:["Please refer to the D-Robotics official documentation ",(0,r.jsx)(t.a,{href:"https://developer.d-robotics.cc/rdk_doc/Robot_development/boxs/function/hobot_clip",children:"https://developer.d-robotics.cc/rdk_doc/Robot_development/boxs/function/hobot_clip"})]})]})}function p(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}},8453:(e,t,o)=>{o.d(t,{R:()=>a,x:()=>s});var n=o(6540);const r={},i=n.createContext(r);function a(e){const t=n.useContext(i);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),n.createElement(i.Provider,{value:t},e.children)}}}]);