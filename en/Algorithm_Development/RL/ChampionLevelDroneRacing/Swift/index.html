<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Algorithm_Development/RL/ChampionLevelDroneRacing/Swift" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Swift | UTMSYS</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://wiki.utmsys.org/en/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://wiki.utmsys.org/en/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://wiki.utmsys.org/en/Algorithm_Development/RL/ChampionLevelDroneRacing/Swift"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="zh_Hans"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Swift | UTMSYS"><meta data-rh="true" name="description" content="Source//www.nature.com/articles/s41586-023-06419-4"><meta data-rh="true" property="og:description" content="Source//www.nature.com/articles/s41586-023-06419-4"><link data-rh="true" rel="icon" href="/en/img/logo.png"><link data-rh="true" rel="canonical" href="https://wiki.utmsys.org/en/Algorithm_Development/RL/ChampionLevelDroneRacing/Swift"><link data-rh="true" rel="alternate" href="https://wiki.utmsys.org/Algorithm_Development/RL/ChampionLevelDroneRacing/Swift" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://wiki.utmsys.org/en/Algorithm_Development/RL/ChampionLevelDroneRacing/Swift" hreflang="en"><link data-rh="true" rel="alternate" href="https://wiki.utmsys.org/Algorithm_Development/RL/ChampionLevelDroneRacing/Swift" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"9. Algorithm Development","item":"https://wiki.utmsys.org/en/09_Algorithm_Development"},{"@type":"ListItem","position":2,"name":"9.6 RL","item":"https://wiki.utmsys.org/en/06_RL"},{"@type":"ListItem","position":3,"name":"Swift","item":"https://wiki.utmsys.org/en/Algorithm_Development/RL/ChampionLevelDroneRacing/Swift"}]}</script><link rel="stylesheet" href="/en/assets/css/styles.194bd4cc.css">
<script src="/en/assets/js/runtime~main.a06974fe.js" defer="defer"></script>
<script src="/en/assets/js/main.ff4cfaf0.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/en/"><div class="navbar__logo"><img src="/en/img/logo.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/en/img/logo.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">UTMSYS</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/en/01_Product_Overview">Start</a><a href="https://www.utmsys.org/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Community<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/utmsys/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/Algorithm_Development/RL/ChampionLevelDroneRacing/Swift" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-Hans">简体中文</a></li><li><a href="/en/Algorithm_Development/RL/ChampionLevelDroneRacing/Swift" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/01_Product_Overview">1. Product Overview</a><button aria-label="Expand sidebar category &#x27;1. Product Overview&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/02_Hardware_Connection">2. Hardware Connection</a><button aria-label="Expand sidebar category &#x27;2. Hardware Connection&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/03_Image_Flash">3. Image Flashing</a><button aria-label="Expand sidebar category &#x27;3. Image Flashing&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/04_Terminal_Access">4. Terminal Access</a><button aria-label="Expand sidebar category &#x27;4. Terminal Access&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/05_System_Config">5. System Configuration</a><button aria-label="Expand sidebar category &#x27;5. System Configuration&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/06_Software_Install">6. Software Installation</a><button aria-label="Expand sidebar category &#x27;6. Software Installation&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/07_Data_Communication">7. Data Communication</a><button aria-label="Expand sidebar category &#x27;7. Data Communication&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/08_Application_Development">8. Application Development</a><button aria-label="Expand sidebar category &#x27;8. Application Development&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/en/09_Algorithm_Development">9. Algorithm Development</a><button aria-label="Collapse sidebar category &#x27;9. Algorithm Development&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/en/01_CV">9.1 CV</a><button aria-label="Expand sidebar category &#x27;9.1 CV&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/en/02_MISSION">9.2 MISSION</a><button aria-label="Expand sidebar category &#x27;9.2 MISSION&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/en/03_PLANNER">9.3 PLANNER</a><button aria-label="Expand sidebar category &#x27;9.3 PLANNER&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/en/04_SLAM">9.4 SLAM</a><button aria-label="Expand sidebar category &#x27;9.4 SLAM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/en/05_SIMULATOR">9.5 Simulator</a><button aria-label="Expand sidebar category &#x27;9.5 Simulator&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/en/06_RL">9.6 RL</a><button aria-label="Collapse sidebar category &#x27;9.6 RL&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/en/Algorithm_Development/RL/ChampionLevelDroneRacing/Swift">ChampionLevelDroneRacing</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/en/Algorithm_Development/RL/ChampionLevelDroneRacing/Swift">Swift</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/en/Algorithm_Development/RL/DifferentiablePhysicsDrone/DiffPhysDrone">DifferentiablePhysicsDrone</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/en/Algorithm_Development/RL/LearningSafeFlight/NavRL">LearningSafeFlight</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/en/07_VLM">9.7 VLM</a><button aria-label="Expand sidebar category &#x27;9.7 VLM&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/en/08_HPC">9.8 HPC</a><button aria-label="Expand sidebar category &#x27;9.8 HPC&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/10_Debug_Commands">10. Debug Commands</a><button aria-label="Expand sidebar category &#x27;10. Debug Commands&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/11_Concepts">11. Concepts</a><button aria-label="Expand sidebar category &#x27;11. Concepts&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/12_FAQ">12. FAQ</a><button aria-label="Expand sidebar category &#x27;12. FAQ&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/en/13_Release">13. Release</a><button aria-label="Expand sidebar category &#x27;13. Release&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/en/UTMSYS">UTMSYS</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/en/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/en/09_Algorithm_Development"><span>9. Algorithm Development</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/en/06_RL"><span>9.6 RL</span></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">ChampionLevelDroneRacing</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Swift</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Swift</h1></header><p>Source: <a href="https://www.nature.com/articles/s41586-023-06419-4" target="_blank" rel="noopener noreferrer">https://www.nature.com/articles/s41586-023-06419-4</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="abstract">Abstract<a href="#abstract" class="hash-link" aria-label="Direct link to Abstract" title="Direct link to Abstract">​</a></h2>
<p>First-person perspective (FPV) drone racing is a televised sport in which professional competitors pilot high-speed aircraft across a 3D track. Each pilot observes the surrounding environment from the drone&#x27;s perspective using video feeds from an onboard camera. Achieving the level of autonomous drone control achieved by professional pilots is challenging because the robot needs to fly within limits while estimating its speed and position on the track using only onboard sensors[^1]. Here we present Swift, an autonomous system that can race against human world champion-level physical vehicles. The system combines deep reinforcement learning (RL) in simulation with data collected in the real world. Swift competed in real-world head-to-head races against three human champions, including two world champions from international leagues. Swift won several races against each human champion and set the fastest race time. This work represents a milestone in mobile robotics and machine intelligence[^2] and may inspire the deployment of hybrid learning-based solutions in other physical systems.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="main">Main<a href="#main" class="hash-link" aria-label="Direct link to Main" title="Direct link to Main">​</a></h2>
<p>Deep reinforcement learning [^3] has driven some of the recent advances in artificial intelligence. Policies trained using deep reinforcement learning have outperformed humans in complex competitive games, including Atari <sup><font dir="auto"><font dir="auto"><font dir="auto">4, 5, 6 </font></font></font></sup> <sup><font dir="auto"><font dir="auto"><font dir="auto">, </font></font></font></sup> <sup><a title="Schrittwieser, J. et al. Mastering Atari, Go, chess, and shogi by planning with learned models. Nature 588, 604–609 (2020)." href="https://www.nature.com/articles/#ref-CR5"><font dir="auto"><font dir="auto"><font dir="auto">Go </font></font></font></a></sup> <sup><a aria-label="References 6" title="Ecoffet, A., Huizinga, J., Lehman, J., Stanley, KO &amp; Clune, J. Return first, explore later. Nature 590, 580–586 (2021)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR6"><font dir="auto"><font dir="auto"><font dir="auto">5, 7, 8, 9 </font></font></font></a></sup> <sup><a title="Mnih, V. et al. Towards human-level control through deep reinforcement learning. Nature 518, 529–533 (2015)." href="https://www.nature.com/articles/#ref-CR4"><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">,</font></font></font></font></a></sup> Chess 5 <sup><a title="Silver, D. 等人。《利用深度神经网络和树形搜索掌握围棋游戏》。《自然》529, 484–489 (2016)。" href="https://www.nature.com/articles/#ref-CR7"><font dir="auto"><font dir="auto">, </font></font></a></sup> <sup><a aria-label="References 5" title="Schrittwieser, J. et al. Mastering Atari, Go, chess, and shogi by planning with learned models. Nature 588, 604–609 (2020)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR5"><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">9</font></font></font></font></a></sup><sup><font dir="auto"><font dir="auto"><font dir="auto">, </font></font></font></sup> <sup><font dir="auto"><font dir="auto"><font dir="auto">StarCraft</font></font></font></sup> [^10] <sup><font dir="auto"><font dir="auto">, </font></font></sup> <sup><a title="Silver, D. 等人。无需人类知识即可掌握围棋游戏。《自然》550, 354–359 (2017)。" href="https://www.nature.com/articles/#ref-CR8"><font dir="auto"><font dir="auto">Dota</font></font></a></sup> 2 <sup><a aria-label="参考文献 5" title="Schrittwieser, J. 等人。通过学习模型进行规划，掌握雅达利、围棋、国际象棋和将棋。《自然》588, 604–609 (2020)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR5"><font dir="auto"><font dir="auto"><font dir="auto">( </font></font></font></a></sup> <sup><a aria-label="参考文献 9" title="Silver, D. 等人。一种通过自我对弈掌握国际象棋、将棋和围棋的通用强化学习算法。Science 362, 1140–1144 (2018)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR9"><font dir="auto"><font dir="auto"><font dir="auto">Ref</font></font></font></a></sup>. [^11] <sup><font dir="auto"><font dir="auto">) </font></font></sup> <sup><font dir="auto"><font dir="auto">, and</font></font></sup> Gran Turismo <sup><a aria-label="参考文献 12" title="Fuchs, F.、Song, Y.、Kaufmann, E.、Scaramuzza, D. 和 Dürr, P. 利用深度强化学习在 Gran Turismo Sport 中实现超人表现。IEEE Robot. Autom. Lett. 6, 4257–4264 (2021)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR12"><font dir="auto"><font dir="auto">12, 13. These impressive </font></font></a></sup> <sup><a aria-label="参考文献 11" title="Berner, C. 等人。基于大规模深度强化学习的 Dota 2。预印本链接：https://arxiv.org/abs/1912.06680 (2019)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR11"><font dir="auto"><font dir="auto"><font dir="auto">demonstrations of machine intelligence have been primarily limited to simulations and</font></font></font></a></sup> <sup><a aria-label="参考文献 13" title="Wurman, PR 等人。利用深度强化学习超越 Gran Turismo 赛车冠军车手。《自然》602, 223–228 (2022)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR13"><font dir="auto"><font dir="auto">board game environments that allow for policy search in precisely replicated test conditions. Overcoming this limitation and demonstrating championship-level performance in competitive sports is a </font></font></a></sup> <sup><a aria-label="参考文献 16" title="Won, D.-O.、Müller, K.-R. 和 Lee, S.-W. 自适应深度强化学习框架使冰壶机器人在现实条件下具有类似人类的表现。《机器人科学》5, eabb9764 (2020)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR16"><font dir="auto"><font dir="auto">long - </font></font></a></sup> <sup><a title="Spielberg, NA, Brown, M., Kapania, NR, Kegelman, JC &amp; Gerdes, JC. 用于高性能自动驾驶的神经网络车辆模型。《机器人科学》，第4卷，eaaw1975期（2019）。" href="https://www.nature.com/articles/#ref-CR15"><font dir="auto"><font dir="auto">standing</font></font></a></sup> <sup><font dir="auto"><font dir="auto">problem</font></font></sup> in autonomous mobile robotics and artificial intelligence <sup><a title="Funke, J. 等人在 2012 IEEE 智能汽车研讨会论文集 541–547 中（IEEE，2012 年）。" href="https://www.nature.com/articles/#ref-CR14"><font dir="auto"><font dir="auto">14, 15, 16</font></font></a></sup><sup><font dir="auto"><font dir="auto">.</font></font></sup></p>
<p>FPV drone racing is a televised sport in which highly trained human pilots push aircraft to their physical limits through high-speed, agile maneuvers (Figure <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig1" target="_blank" rel="noopener noreferrer">1a</a> ). The aircraft used in FPV racing are quadcopters, which are among the most agile machines ever created (Figure <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig1" target="_blank" rel="noopener noreferrer">1b</a> ). During competition, the aircraft exert forces exceeding five times their own weight or more, reaching speeds exceeding 100 km h⁻¹ <sup><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">and</font></font></font></font></sup> accelerations several times greater than gravity, even in confined spaces. Each aircraft is remotely controlled by a human pilot wearing a headset that displays a video stream from an onboard camera, creating an immersive &quot;first-person perspective&quot; experience (Figure <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig1" target="_blank" rel="noopener noreferrer">1c</a> ).</p>
<p><img decoding="async" loading="lazy" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-023-06419-4/MediaObjects/41586_2023_6419_Fig1_HTML.png?as=webp" alt="Figure 1" class="img_ev3q"></p>
<p>Figure 1: Drone racing.</p>
<p>Attempts to create autonomous systems that can match the performance of human pilots can be traced back to the first autonomous drone race in 2016 (Ref. [^17] <sup><a aria-label="Reference 17" title="Moon, H., Sun, Y., Baltes, J., and Kim, SJ. “IROS 2016 Competition.” IEEE Robot. Autom. Mag. 24, 20–29 (2017)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR17"><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">)</font></font></font></font></a></sup>. A series of innovations followed, including using deep networks to identify the next gate location, <sup><font dir="auto"><font dir="auto">18,19,20 </font></font></sup> <sup><a aria-label="Reference 20" title="Zhang, D. and Doyle, D.D., in Proc. 2020 IEEE Conference on Aeronautics and Astronautics, 1–11 (IEEE, 2020)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR20"><font dir="auto"><font dir="auto"><font dir="auto">transferring </font></font></font></a></sup> <sup><a title="Jung, S., Hwang, S., Shin, H. &amp; Shim, DH, 基于深度学习的室内自主无人机竞速感知、制导和导航。IEEE Robot. Autom. Lett. 3, 2539–2544 (2018)。" href="https://www.nature.com/articles/#ref-CR18"><font dir="auto"><font dir="auto"><font dir="auto">race</font></font></font></a></sup> <sup><font dir="auto"><font dir="auto"><font dir="auto">strategies </font></font></font></sup> <sup><a aria-label="参考文献 24" title="Li, S., van der Horst, E., Duernay, P., De Wagter, C. &amp; de Croon, GC. 视觉模型预测定位，实现72g无人机高效自主竞速。《J. Field Robot》杂志，第37卷，第667–692页（2020年）。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR24"><font dir="auto"><font dir="auto">from</font></font></a></sup> simulation to reality <sup><font dir="auto"><font dir="auto">,21,22 </font></font></sup> <sup><a aria-label="参考文献 21" title="Loquercio, A. 等人。深度无人机竞速：通过领域随机化从模拟到现实。IEEE 机器人学报，36, 1–14 (2019)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR21"><font dir="auto"><font dir="auto"><font dir="auto">and</font></font></font></a></sup> accounting for uncertainty in perception, <sup><a aria-label="参考文献 25" title="人工智能正在驾驶无人机（速度非常非常慢）。https://www.nytimes.com/2019/03/26/technology/alphapilot-ai-drone-racing.html (2019)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR25"><font dir="auto"><font dir="auto"><font dir="auto">23,24</font></font></font></a></sup><sup><font dir="auto"><font dir="auto">. The 2019 </font></font></sup> <sup><a aria-label="参考文献 23" title="Kaufmann，E.等人在2019年国际机器人与自动化会议（ICRA）第690–696期（IEEE，2019年）中。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR23"><font dir="auto"><font dir="auto"><font dir="auto">AlphaPilot</font></font></font></a></sup> autonomous drone race showcased some of the best research in this area.25 However, the top two teams still took almost twice as long as professional human pilots to complete the course.26,27 <sup><a aria-label="参考文献 27" title="Wagter, CD, Paredes-Vallé, F., Sheth, N. 和 de Croon, G. 2019 年人工智能机器人竞赛获胜作品背后的感知、状态估计和控制。《野外机器人》。2, 1263–1290 (2022)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR27"><font dir="auto"><font dir="auto">More </font></font></a></sup> <sup><a aria-label="参考文献 22" title="Loquercio, A. 等人。《学习野外高速飞行》。《机器人科学》，第 6 卷，eabg5810 页（2021 年）。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR22"><font dir="auto"><font dir="auto">recently </font></font></a></sup> <sup><a aria-label="参考文献 26" title="Foehn, P. 等人。AlphaPilot：自主无人机竞速。Auton. Robots 46, 307–320 (2021)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR26"><font dir="auto"><font dir="auto"><font dir="auto">,</font></font></font></a></sup> autonomous systems have begun to match the performance of human experts.28,29,30 <sup><font dir="auto"><font dir="auto">However, these efforts rely </font></font></sup> <sup><a title="Foehn, P.、Romero, A. 和 Scaramuzza, D. 四旋翼航点飞行的时间最优规划。《机器人科学》，第 6 卷，eabh1221 页（2021 年）。" href="https://www.nature.com/articles/#ref-CR28"><font dir="auto"><font dir="auto"><font dir="auto">on</font></font></font></a></sup> <sup><font dir="auto"><font dir="auto">near- perfect state estimates </font></font></sup> <sup><font dir="auto"><font dir="auto">provided by external motion capture systems. This makes </font></font></sup> <sup><a title="Romero, A.、Sun, S.、Foehn, P. 和 Scaramuzza, D. 时间最优四旋翼飞行的模型预测轮廓控制。IEEE 机器人学报，38, 3340–3356 (2022)。" href="https://www.nature.com/articles/#ref-CR29"><font dir="auto"><font dir="auto">comparisons with human pilots </font></font></a></sup> <sup><a aria-label="参考文献 30" title="Sun, S., Romero, A., Foehn, P., Kaufmann, E. &amp; Scaramuzza, D. 非线性MPC与基于差分平坦度的四旋翼敏捷飞行控制比较研究。IEEE机器人学报，38, 3357–3373 (2021)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR30"><font dir="auto"><font dir="auto">unfair</font></font></a></sup>, as humans only have access to onboard observations from the drone.</p>
<p>This paper introduces Swift, an autonomous flight system that can fly a quadrotor in a competition against a human world champion using only onboard sensors and computational power. Swift consists of two key modules: (1) a perception system that converts high-dimensional visual and inertial information into low-dimensional representations; and (2) a control policy that takes the low-dimensional representations generated by the perception system and generates control commands.</p>
<p>The control policy is represented by a feedforward neural network and trained in simulation using model-free on-policy deep reinforcement learning [^31]. To bridge the gap between the simulation and the physical world in terms of perception and dynamics, we utilize non-parametric empirical noise models estimated from data collected from the physical system. These empirical noise models have been shown to be crucial for successfully transferring control policies from simulation to the real world.</p>
<p>We evaluated Swift on a physical track designed by professional drone racing pilots (Figure <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig1" target="_blank" rel="noopener noreferrer">1a</a> ). The track consisted of seven square gates measuring 30 × 30 × 8 meters, forming a 75-meter lap. Swift competed against three human champions on this track: 2019 Drone Racing League World Champion Alex Vanover, two-time MultiGP International Open World Cup champion Thomas Bitmatta, and three-time Swiss National Champion Marvin Schaepper. The quadrotors used by Swift and the human pilots had the same weight, shape, and propulsion. They are similar to drones used in international competitions.</p>
<p>The human pilots practiced on the track for a week. Afterward, each pilot competed in several head-to-head races against Swift (Figures <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig1" target="_blank" rel="noopener noreferrer">1a, b</a> ). In each head-to-head race, two drones (one controlled by a human pilot and one by Swift) started from the podium. The race began with an acoustic signal. The first drone to complete three full laps of the track, passing through all gates in the correct order on each lap, won the race.</p>
<p>Swift defeated every human pilot in the competition and set the fastest time in the event. To our knowledge, this is the first time an autonomous mobile robot has achieved world championship-level performance in a real-world competitive sport.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="swift">Swift<a href="#swift" class="hash-link" aria-label="Direct link to Swift" title="Direct link to Swift">​</a></h2>
<p>Swift combines learning-based and traditional algorithms to map onboard sensor readings to control commands. This mapping consists of two parts: (1) an observation strategy, which distills high-dimensional visual and inertial information into a task-specific, low-dimensional encoding; and (2) a control strategy, which converts the encoding into instructions for the drone. A schematic diagram of the system is shown in Figure <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig2" target="_blank" rel="noopener noreferrer">2</a>.</p>
<p><img decoding="async" loading="lazy" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-023-06419-4/MediaObjects/41586_2023_6419_Fig2_HTML.png?as=webp" alt="Figure 2" class="img_ev3q"></p>
<p>Figure 2: Swift system.</p>
<p>The observation policy consists of a visual-inertial estimator <sup><a aria-label="Reference 32" title="Scaramuzza, D. and Zhang, Z. Encyclopedia of Robotics (Ang, M., Khatib, O. and Siciliano, B. eds.) 1–9 (Springer, 2019)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR32"><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">32, 33</font></font></font></font></a><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">, which </font></font></font></font></sup> <sup><a aria-label="Reference 26" title="Foehn, P. et al. AlphaPilot: Autonomous drone racing. Auton. Robots 46, 307–320 (2021)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR26"><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">operates in conjunction</font></font></font></font></a></sup> with a gate detector 26, a convolutional neural network that <sup><a aria-label="Reference 33" title="Huang, G. In Proceedings of the 2019 International Conference on Robotics and Automation (ICRA) 9572–9582 (IEEE, 2019)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR33"><font dir="auto"><font dir="auto"><font dir="auto">detects</font></font></font></a></sup> race gates in the onboard imagery. The detected gates are then used to estimate the drone&#x27;s global position and orientation along the track. This is done using a camera resection algorithm [^34] in conjunction with the track map. The global pose estimate obtained from the gate detector is then combined with the estimate from the visual-inertial estimator via a Kalman filter to more accurately represent the robot&#x27;s state. The control policy is represented by a two-layer perceptron that maps the output of the Kalman filter to control commands for the drone. The policy is <sup><a aria-label="Reference 31" title="Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O. Proximal Policy Optimization Algorithms. Preprint link: https://arxiv.org/abs/1707.06347 (2017)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR31"><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">trained in simulation using policy-based model-free deep reinforcement learning 31. During training, the policy maximizes</font></font></font></font></a></sup> the reward for approaching the next race gate [^35] combined with the perceptual goal of keeping the next gate within the camera&#x27;s field of view. Seeing the next gate is rewarded because it increases the accuracy of the pose estimate.</p>
<p>Optimizing a policy solely through simulation can lead to poor performance on physical hardware if the discrepancies between simulation and reality are not eliminated. These discrepancies are primarily due to two factors: (1) the difference between simulated and real-world dynamics, and (2) the noisy estimate of the robot state made by the observation policy when fed real-world sensor data. We mitigate these discrepancies by collecting a small amount of real-world data and leveraging this data to improve the realism of the simulator.</p>
<p>Specifically, as the UAV drives around the track, we record observations from the robot’s onboard sensors along with high-precision pose estimates from a motion capture system. During this data collection phase, the robot is controlled by a policy trained in simulation that operates on the pose estimates provided by the motion capture system. The recorded data allows the identification of characteristic failure modes in perception and dynamics observed through the track. The complexity of these perception failures and unmodeled dynamics depends on the environment, platform, track, and sensors. Perception and dynamic residuals are modeled using Gaussian processes [^36] and <em>k-</em> nearest neighbor regression, respectively. This choice is motivated by our empirical finding that perception residuals are stochastic, while dynamic residuals are largely deterministic (Extended Data Fig. <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig5" target="_blank" rel="noopener noreferrer">1</a> ). These residual models are integrated into the simulation, and the racing policy is fine-tuned in this augmented simulation. This approach is related to the empirical actuator model used for simulation-to-reality transfer in Ref. [^37] but goes further by incorporating empirical modeling of the perception system and accounting for the stochastic nature of the platform state estimates.</p>
<p>We eliminated each component of Swift in controlled experiments reported in the Extended Data. Furthermore, we compared it with recent work using traditional methods, including trajectory planning and model predictive control (MPC), to solve autonomous drone racing tasks. While such methods achieve comparable or even superior performance to ours under ideal conditions (such as simplified dynamics and perfect knowledge of the robot&#x27;s state), their performance collapses when their assumptions are violated. We found that <sup><a aria-label="参考文献 29" title="Romero, A.、Sun, S.、Foehn, P. 和 Scaramuzza, D. 时间最优四旋翼飞行的模型预测轮廓控制。IEEE 机器人学报，38, 3340–3356 (2022)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR29"><font dir="auto"><font dir="auto"><font dir="auto">methods that rely on precomputed paths28 </font></font></font></a></sup> <sup><a aria-label="Reference 28" title="Foehn, P., Romero, A. and Scaramuzza, D. Time-optimal planning of waypoint flight for quadrotors. Robotics, vol. 6, p. eabh1221 (2021)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR28"><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">, 29</font></font></font></font></a></sup> <sup><font dir="auto"><font dir="auto"><font dir="auto">are particularly sensitive to noisy perception and dynamics. Even equipped with high-precision state estimates from motion capture systems, traditional methods</font></font></font></sup> fail to achieve lap times competitive with Swift or human world champions. Detailed analysis is provided in the Extended Data.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="results">Results<a href="#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results">​</a></h2>
<p>Drone races are conducted on courses designed by external, world-class FPV pilots. These courses are filled with unique maneuvers and challenges, such as the Split-S (Figure <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig1" target="_blank" rel="noopener noreferrer">1a</a> (top right) and <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig4" target="_blank" rel="noopener noreferrer">Figure 4d</a> ). Even in the event of a collision, pilots can continue the race, provided their drones are still able to fly. If both drones collide and are unable to complete the race, the drone that travels further on the course wins.</p>
<p><a href="https://www.nature.com/articles/s41586-023-06419-4#Fig3" target="_blank" rel="noopener noreferrer">As shown in Figure 3b</a>, Swift won 5 of 9 races against A. Vanover, 4 of 7 against T. Bitmatta, and 6 of 9 against M. Schaepper. Of Swift&#x27;s 10 losses, 40% were due to collisions with opponents, 40% were due to collisions with gates, and 20% were due to the drone being slower than the human pilot. Overall, Swift won every race against the human pilot. Swift also set the fastest time, beating the best time by a human pilot (A. Vanover) by half a second.</p>
<p><img decoding="async" loading="lazy" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-023-06419-4/MediaObjects/41586_2023_6419_Fig3_HTML.png?as=webp" alt="Figure 3" class="img_ev3q"></p>
<p><strong>Figure 3: Results.</strong></p>
<p>Figure <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig4" target="_blank" rel="noopener noreferrer">4</a> and Extended Data Table <a href="https://www.nature.com/articles/s41586-023-06419-4#Tab1" target="_blank" rel="noopener noreferrer">1d</a> analyze the fastest laps flown by Swift and each human pilot. Although Swift was faster overall than all human pilots, it was not faster on all individual sections of the track (Extended Data Table <a href="https://www.nature.com/articles/s41586-023-06419-4#Tab1" target="_blank" rel="noopener noreferrer">1</a> ). Swift was consistently faster at the start and in tight turns, such as the forked S. At the start, Swift had a shorter reaction time, starting 120 milliseconds earlier than the human pilots on average. Furthermore, it accelerated faster, reaching a higher speed when entering the first gate (Extended Data Table <a href="https://www.nature.com/articles/s41586-023-06419-4#Tab1" target="_blank" rel="noopener noreferrer">1d</a>, segment 1). In tight turns, <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig4" target="_blank" rel="noopener noreferrer">as shown in Figures 4c and 4d, Swift was able to find more compact maneuvers. One hypothesis is that Swift optimizes its trajectory over longer timescales than the human pilots. Model-free RL is known to</a> optimize long-term rewards via a value function [^38]. In contrast, human pilots plan their movements over shorter timescales, at most one gate ahead [^39]. This is evident , for example, in segment S (Figure <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig4" target="_blank" rel="noopener noreferrer">4b, d</a> ), where the human pilot was faster at the beginning and end of the maneuver but slower overall (Extended Data Table <a href="https://www.nature.com/articles/s41586-023-06419-4#Tab1" target="_blank" rel="noopener noreferrer">1d</a>, segment 3). Furthermore, the human pilot maneuvered the aircraft toward the next gate earlier than Swift (Figure <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig4" target="_blank" rel="noopener noreferrer">4c, d</a> ). We believe that the human pilot was accustomed to keeping the upcoming gate in view, while Swift had learned to rely on other cues for certain maneuvers, such as inertial data and visual odometry for features in the surrounding environment. Overall, averaged across the entire course, the autonomous drone achieved the highest average speed, found the shortest course, and managed to keep the aircraft closer to its driving limit throughout the race, as shown by average thrust and power (Extended Data Table <a href="https://www.nature.com/articles/s41586-023-06419-4#Tab1" target="_blank" rel="noopener noreferrer">1d</a> ).</p>
<p><img decoding="async" loading="lazy" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-023-06419-4/MediaObjects/41586_2023_6419_Fig4_HTML.png?as=webp" alt="Figure 4" class="img_ev3q"></p>
<p><strong>Figure 4: Analysis.</strong></p>
<p>We also compared Swift&#x27;s performance with that of a human champion in a time trial (Figure <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig3" target="_blank" rel="noopener noreferrer">3a</a> ). In a time trial, a single pilot races around a track, completing laps at the pilot&#x27;s discretion. We accumulated time trial data from practice weeks and races, including training runs (Figure <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig3" target="_blank" rel="noopener noreferrer">3a</a>, color) and laps flown under race conditions (Figure <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig3" target="_blank" rel="noopener noreferrer">3a</a>, black). For each competitor, we used over 300 laps to calculate statistics. The autonomous drone more consistently pursued faster lap times, exhibiting lower mean and variance. In contrast, the human pilot made lap-by-lap decisions about whether to pursue speed, both during training and during the race, resulting in higher mean and variance lap times. The ability to adjust flight strategy allows the human pilot to maintain a slower speed when they find themselves significantly ahead, reducing the risk of a crash. The autonomous drone, unaware of its opponent, will always strive for the fastest expected finish time, potentially taking too much risk when ahead and too little risk when trailing by <sup><a aria-label="Reference 40" title="Spica, R., Cristofalo, E., Wang, Z., Montijano, E., and Schwager, M. A real-time game-theoretic planner for autonomous two-player drone racing. IEEE Transactions on Robotics, 36, 1389–1403 (2020)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR40"><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">40 seconds</font></font></font></font></a></sup>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="discussion">Discussion<a href="#discussion" class="hash-link" aria-label="Direct link to Discussion" title="Direct link to Discussion">​</a></h2>
<p>FPV drone racing requires real-time decision-making based on noisy and incomplete sensory input from the physical environment. We propose an autonomous physical system that can achieve championship-level performance in this sport, matching and sometimes exceeding the performance of human world champions. Our system has certain structural advantages over human pilots. First, it utilizes inertial data from an onboard inertial measurement unit32 <sup><a aria-label="Reference 32" title="Scaramuzza, D. and Zhang, Z. Encyclopedia of Robotics (Ang, M., Khatib, O. and Siciliano, B. eds.) 1–9 (Springer, 2019)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR32"><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">.</font></font></font></font></a></sup> This is similar to the human vestibular system[^41], which human pilots do not use because they are not in the aircraft and cannot feel the accelerations acting on it. Second, our system benefits from lower sensorimotor latency (40 milliseconds for Swift, compared to an average of 220 milliseconds for professional human pilots[^39]). On the other hand, the limited refresh rate of the camera used by Swift (30 Hz) can be considered a structural advantage over human pilots, whose camera refresh rate is four times higher than that of human pilots (120 Hz), thereby improving their reaction time[^42].</p>
<p>Human pilots are impressively robust: they can continue flying and completing the track even after a full-speed crash—if the hardware is still functioning properly. Swift was not trained to recover from a crash. Human pilots are also very robust to changes in environmental conditions (e.g., lighting), which can significantly change the appearance of the track. In contrast, Swift&#x27;s perception system assumes that the appearance of the environment is consistent with what was observed during training. If this assumption is not met, the system fails. Robustness to appearance changes can be provided by training the gate detector and the residual observation model under multiple conditions. Addressing these limitations allows the proposed method to be applied to autonomous drone racing, where access to the environment and the drone is limited[^25].</p>
<p>While many limitations remain and further research is needed, the achievement of world championship-level performance in a popular sport by an autonomous mobile robot is undoubtedly a milestone in robotics and machine intelligence. This work may inspire the widespread application of hybrid learning-based solutions in other physical systems, such as autonomous ground vehicles, aerial vehicles, and personal robots.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="methods">Methods<a href="#methods" class="hash-link" aria-label="Direct link to Methods" title="Direct link to Methods">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="quadrotor">Quadrotor<a href="#quadrotor" class="hash-link" aria-label="Direct link to Quadrotor" title="Direct link to Quadrotor">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="quadrotor-1">Quadrotor<a href="#quadrotor-1" class="hash-link" aria-label="Direct link to Quadrotor" title="Direct link to Quadrotor">​</a></h4>
<p>To enable large-scale training, we use a high-fidelity simulation of quadrotor dynamics. This section briefly describes the simulation process. The dynamics of the aircraft can be expressed as</p>
<p>$x˙=[p˙WBq˙WBv˙Wω˙BΩ˙]=[vWqWB⋅[0ωB/2]1m(qWB⊙(fprop+faero))+gWJ−1(τprop+τmot+τaero+τiner)1kmot(Ωss−Ω)],$</p>
<p>$fprop=∑ifi,τprop=∑iτi+rP,i×fi,$</p>
<p>（2）</p>
<p>$τmot=Jm+p∑iζiΩ˙i,τiner=−ωB×JωB$</p>
<p>（3）</p>
<p>$fi(Ωi)=[00cl⋅Ωi2]⊤,τi(Ωi)=[00cd⋅Ωi2]⊤$</p>
<p>（4）</p>
<p>where <em>c</em> <sub><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">l</font></font></font></font></sub> and <em>c</em> <sub><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">d</font></font></font></font></sub> represent the propeller lift coefficient and drag coefficient, respectively.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="aerodynamics-and">Aerodynamics and<a href="#aerodynamics-and" class="hash-link" aria-label="Direct link to Aerodynamics and" title="Direct link to Aerodynamics and">​</a></h4>
<p>$fx∼vx+vx|vx|+Ω2¯+vxΩ2¯fy∼vy+vy|vy|+Ω2¯+vyΩ2¯fz∼vz+vz|vz|+vxy+vxy2+vxyΩ2¯+vzΩ2¯+vxyvzΩ2¯τx∼vy+vy|vy|+Ω2¯+vyΩ2¯+vy|vy|Ω2¯τy∼vx+vx|vx|+Ω2¯+vxΩ2¯+vx|vx|Ω2¯τz∼vx+vy$</p>
<p>We then identify the corresponding coefficients from real flight data and use motion capture technology to provide ground-truth force and torque measurements. We then use data from the track to fit the dynamics model to the track. This is similar to the training a human pilot would perform on a specific track in the days or weeks before a race. In our case, the human pilot would practice on the same track for a week before the race.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="betaflight-low-level">Betaflight low-level<a href="#betaflight-low-level" class="hash-link" aria-label="Direct link to Betaflight low-level" title="Direct link to Betaflight low-level">​</a></h4>
<p>To control the quadrotor, the neural network outputs the total thrust and body velocity. Such control signals are known to be highly flexible and robust, making them easy to translate from simulation to reality[^44]. The predicted total thrust and body velocity are then processed by an onboard low-level controller, which calculates the individual motor commands and then converts these commands into analog voltage signals via the electronic speed controllers (ESCs) that control the motors. On the real aircraft, this low-level proportional-integral-derivative (PID) controller and ESC are implemented using open-source Betaflight and BLHeli32 firmware[^45]. In the simulation, we use accurate models of the low-level controller and motor speed controllers.</p>
<p>Because the Betaflight PID controller is optimized for manned flight, it exhibits certain idiosyncrasies that simulation accurately captures: the D term&#x27;s reference value is always zero (pure damping), the I term resets when the throttle is closed, and in the event of motor thrust saturation, airframe rate control takes priority (all motor signals are scaled down to avoid saturation). The controller gains used for simulation were identified from detailed logs of the Betaflight controller&#x27;s internal states. Simulation was able to predict individual motor commands with an error of less than 1%.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="battery-model-and">Battery Model and<a href="#battery-model-and" class="hash-link" aria-label="Direct link to Battery Model and" title="Direct link to Battery Model and">​</a></h4>
<p>The underlying controller converts each motor command into a pulse-width modulated (PWM) signal and sends it to the ESC, which controls the motor. Because the ESC does not perform closed-loop control of the motor speed, <sub><i><font dir="auto"><font dir="auto"><font dir="auto">the steady-state motor speed Ω </font></font></font></i></sub> <sub><i><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">i</font></font></font></font></i><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">,ss, given a PWM motor command cmd i, is a function of the battery voltage. Therefore, our simulation uses a gray-box battery model</font></font></font></font></sub> [^46] to model the battery voltage, which simulates the voltage based on the instantaneous power consumption <em>P</em> <sub><font dir="auto"><font dir="auto"><font dir="auto">mot:</font></font></font></sub></p>
<p>$Pmot=cdΩ3η$</p>
<p>（5）</p>
<p><sub><font dir="auto"><font dir="auto"><font dir="auto">The battery model [^46] then</font></font></font></sub> simulates the battery voltage according to this power demand. Given the battery voltage <em>Ubat</em> and the individual motor commands <em>ucmd</em> <sub><font dir="auto"><font dir="auto"><font dir="auto">, </font></font></font></sub> <sub><i><font dir="auto"><font dir="auto"><font dir="auto">i</font></font></font></i></sub>, we use the mapping (again omitting the coefficients that multiply each summand)</p>
<p>$Ωi,ss∼1+Ubat+ucmd,i+ucmd,i+Ubatucmd,i$</p>
<p>（6）</p>
<p><sub><i><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">Calculate the corresponding steady-state motor speeds Ω i</font></font></font></font></i><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">,ss</font></font></font></font></sub> required for the dynamics simulation in <a href="https://www.nature.com/articles/s41586-023-06419-4#Equ1" target="_blank" rel="noopener noreferrer">Equation (1</a> ). These coefficients have been identified from the Betaflight logs containing the measured values of all relevant quantities. Combined with the low-level controller model, this allows the simulator to correctly convert the actions in the form of total thrust and body velocity into the motor speeds Ω <sub><font dir="auto"><font dir="auto">ss</font></font></sub> <a href="https://www.nature.com/articles/s41586-023-06419-4#Equ1" target="_blank" rel="noopener noreferrer">required in Equation (1)</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="strategy">Strategy<a href="#strategy" class="hash-link" aria-label="Direct link to Strategy" title="Direct link to Strategy">​</a></h3>
<p><strong>We train a deep neural control policy that directly maps observations o</strong> t of the platform state and the next gated observation to control actions <strong>u</strong> <sub><i><font dir="auto"><font dir="auto"><font dir="auto">t in the form of </font></font></font></i></sub> <sub><i><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">mass-normalized collective thrust and body velocity</font></font></font></font></i></sub> [^44]. The control policy is trained in simulation using model-free reinforcement learning.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="training">Training<a href="#training" class="hash-link" aria-label="Direct link to Training" title="Direct link to Training">​</a></h4>
<p><sup><a aria-label="Reference 31" title="Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O. Proximal Policy Optimization Algorithms. Preprint link: https://arxiv.org/abs/1707.06347 (2017)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR31"><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">Training is performed using proximal policy optimization.31</font></font></font></font></a></sup> This “actor-critic” approach requires jointly optimizing two neural networks during training: a policy network (which maps observations to actions) and a value network (which acts as a “critic” and evaluates the actions taken by the policy). After training, simply deploy the policy network on the robot.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="observe-act-and">Observe, act, and<a href="#observe-act-and" class="hash-link" aria-label="Direct link to Observe, act, and" title="Direct link to Observe, act, and">​</a></h4>
<p>$rt=rtprog+rtperc+rtcmd−rtcrash$</p>
<p>（7）</p>
<p>Among them, <em>r</em> <sup><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">prog</font></font></font></font></sup> rewards progress towards the next door [^35]; <em>r</em> <sup><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">perc</font></font></font></font></sup> encodes perception awareness by adjusting the vehicle posture so that the camera&#x27;s optical axis points to the center of the next door; <em>r</em> <sup><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">cmd</font></font></font></font></sup> rewards smooth movement; and <em>r</em> <sup><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">crash</font></font></font></font></sup> is a binary penalty that only takes effect when colliding with a door or the platform leaves the predefined bounding box. If <em>r</em> <sup><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">crash</font></font></font></font></sup> is triggered, the training process ends.</p>
<p>Specifically, the reward terms are as follows</p>
<p>$rtprog=λ1[dt−1Gate−dtGate]rtperc=λ2exp⁡[λ3⋅δcam4]$</p>
<p>（8）</p>
<p>$rtcmd=λ4atω+λ5∥at−at−1∥2$</p>
<p>（9）</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="training-1">Training<a href="#training-1" class="hash-link" aria-label="Direct link to Training" title="Direct link to Training">​</a></h4>
<p>Data collection is performed in parallel by simulating 100 agents that interact with the environment in episodes of 1,500 steps. At each environment reset, each agent is initialized at a random gate on the track and generates bounded perturbations around the previously observed state as it passes through this gate. Unlike previous work44,49,50 <sup><a aria-label="参考文献 44" title="Kaufmann, E.、Bauersfeld, L. 和 Scaramuzza, D. 在 2022 年国际机器人与自动化会议 (ICRA) 10504–10510 (IEEE, 2022) 中。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR44"><font dir="auto"><font dir="auto"><font dir="auto">,</font></font></font></a></sup> <sup><font dir="auto"><font dir="auto"><font dir="auto"> we </font></font></font></sup> <sup><a aria-label="Reference 50" title="Andrychowicz, O.M. et al. Learning dexterous hand-held manipulation. International Journal of Robotics Research 39, 3–20 (2020)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR50"><font dir="auto"><font dir="auto"><font dir="auto">do not randomize the platform dynamics </font></font></font></a></sup> <sup><a aria-label="Reference 49" title="Molchanov, A. et al. In Proc. 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 59–66 (IEEE, 2019)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR49"><font dir="auto"><font dir="auto"><font dir="auto">during</font></font></font></a></sup> <sup><font dir="auto"><font dir="auto"><font dir="auto">training</font></font></font></sup>. Instead, we fine-tune on real data. The training environment is implemented using TensorFlow Agents [^51]. Both the policy and value networks are represented by two layers of perceptrons, each with 128 nodes and LeakyReLU activations with a negative slope of 0.2. The network parameters are optimized using the Adam optimizer, with a learning rate of 3 × 10−4 for both the policy and value networks <sup><font dir="auto"><font dir="auto"><font dir="auto">.</font></font></font></sup></p>
<p>Policy training involved a total of 1 × 10 <sup><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">8</font></font></font></font></sup> interactions with the environment and took 50 minutes on a workstation (i9 12900K, RTX 3090, 32 GB RAM DDR5). Fine-tuning involved 2 × 10 <sup><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">7</font></font></font></font></sup> interactions with the environment.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="residual-model">Residual Model<a href="#residual-model" class="hash-link" aria-label="Direct link to Residual Model" title="Direct link to Residual Model">​</a></h3>
<p>We fine-tune the original policy based on a small amount of data collected in the real world. Specifically, we collect three full rollouts in the real world, equivalent to approximately 50 seconds of flight time. We fine-tune the policy by identifying residual observations and residual dynamics, which are then used for simulated training. During this fine-tuning phase, only the weights of the control policy are updated, while the weights of the door detection network remain unchanged.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="residual-observation">Residual Observation<a href="#residual-observation" class="hash-link" aria-label="Direct link to Residual Observation" title="Direct link to Residual Observation">​</a></h4>
<p>High-speed navigation results in severe motion blur, which can cause loss of tracked visual features and lead to significant drift in linear odometry estimates. We fine-tune the policy using an odometry model that is learned from only a small number of trials recorded in the real world. To model the drift in the odometry, we use Gaussian processes [^36] because they can fit the posterior distribution of odometry perturbations, from which we can sample time-consistent realizations.</p>
<p>Specifically, a Gaussian process model fits the residual position, velocity, and pose as a function of the robot&#x27;s ground truth state. Observation residuals are identified by comparing the visual inertial odometry (VIO) estimates observed during real-world rolling with the ground truth platform state obtained from an external motion tracking system.</p>
<p>We treat each dimension of the observations separately, effectively fitting a set of nine one-dimensional Gaussian processes to the observation residuals. We use the hybrid radial basis function kernel</p>
<p>$κ(zi,zj)=σf2exp⁡(−12(zi−zj)⊤L−2(zi−zj))+σn2$</p>
<p>（10）</p>
<p>Where <em>L</em> is the diagonal length scale matrix, <em>σf</em> and <em>σn</em> represent the data and prior noise variances, respectively, <sub><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">and </font></font></font></font></sub> <sub><font dir="auto"><font dir="auto"><font dir="auto">zi </font></font></font></sub> <sub><i><font dir="auto"><font dir="auto"><font dir="auto">and</font></font></font></i></sub> <strong>zj</strong> represent <strong>the</strong> <sub><i><font dir="auto"><font dir="auto"><font dir="auto">data</font></font></font></i></sub> features. Kernel hyperparameters are optimized by maximizing the log-marginal likelihood. After kernel hyperparameter optimization, new realizations are sampled from the posterior distribution and then used to fine-tune the policy. Extended Data Figure <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig5" target="_blank" rel="noopener noreferrer">1</a> shows the residual observations of position, velocity, and pose from a real deployment, along with 100 realizations sampled from the Gaussian process model.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="residual-dynamics">Residual Dynamics<a href="#residual-dynamics" class="hash-link" aria-label="Direct link to Residual Dynamics" title="Direct link to Residual Dynamics">​</a></h4>
<p>We use a residual model to supplement the simulated robot dynamics [^52]. Specifically, we determine the residual acceleration as a function of the platform state <strong>s</strong> and the command mass-normalized total thrust <em>c</em>:</p>
<p>$ares=KNN(s,c)$</p>
<p>（11）</p>
<p>We used <em>k- nearest neighbor regression</em> <em>with k = 5.</em> The size of the dataset used for residual dynamics model identification depends on the track layout and ranges between 800 and 1,000 samples for the track layout used in this study.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="door">Door<a href="#door" class="hash-link" aria-label="Direct link to Door" title="Direct link to Door">​</a></h3>
<p>To correct for drift accumulated by the VIO pipeline, doors are used as different landmarks for relative localization. Specifically, doors are detected in the onboard camera view by segmenting their corners [^26]. Grayscale images provided by the Intel RealSense Tracking Camera T265 are used as input images for the door detector. The architecture of the segmentation network is a six-level U-Net [^53] with (8, 16, 16, 16, 16) convolutional filters of size (3, 3, 3, 5, 7, 7) at each level, and an additional layer operating on the output of the U-Net with 12 filters. LeakyReLU with <em>α</em>  = 0.01 is used as the activation function. For deployment on NVIDIA Jetson TX2, the network was ported to TensorRT. To optimize memory usage and computation time, inference is performed in half-precision mode (FP16) and the image is downsampled to 384 × 384 before being fed into the network. On an NVIDIA Jetson TX2, one forward pass takes 40 milliseconds.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="vio-drift">VIO drift<a href="#vio-drift" class="hash-link" aria-label="Direct link to VIO drift" title="Direct link to VIO drift">​</a></h3>
<p>Odometry estimates from the VIO pipeline54 <sup><a aria-label="Reference 54" title="Intel RealSense T265 Series Product Family. https://www.intelrealsense.com/wp-content/uploads/2019/09/Intel_RealSense_Tracking_Camera_Datasheet_Rev004_release.pdf (2019)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR54"><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">can</font></font></font></font></a></sup> drift significantly during high-speed flight. We use gate detection to stabilize the pose estimates produced by VIO. The gate detector outputs the corner coordinates of all visible gates. We first estimate a relative pose for all predicted gates using infinitesimal plane-based pose estimation (IPPE) [^34]. Based on this relative pose estimate, each gate observation is assigned to the nearest gate in the known trajectory layout, resulting in an estimated pose of the drone.</p>
<p>The state <strong>x</strong> and covariance <em>P</em> updates are given by:</p>
<p>$xk+1=Fxk,Pk+1=FPkF⊤+Q,$</p>
<p>（12）</p>
<p>$F=[I3×3dtI3×303×3I3×3],Q=[σposI3×303×303×3σvelI3×3].$</p>
<p>（13）</p>
<p>$Kk=Pk−Hk⊤(HkPk−Hk⊤+R)−1,xk+=xk−+Kk(zk−H(xk−)),Pk+=(I−KkHk)Pk−,$</p>
<p>（14）</p>
<p>where <em>Kk</em> is the Kalman gain, <sup><i><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">R</font></font></font></font></i></sup> <em>is</em> the measurement covariance, <em>and Hk</em> <sub><i><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">is</font></font></font></font></i></sub> the measurement matrix. If multiple doors are detected in a single camera frame, all relative pose estimates are stacked and processed in the same Kalman filter update step. The primary source of measurement error is the uncertainty in the network&#x27;s door angle detections. When applying IPPE, this error in the image plane contributes to pose error. We chose a sampling-based approach to estimate pose error from the known average door angle detection uncertainty. For each door, the IPPE algorithm is applied to the nominal door observation and 20 perturbed door angle estimates. The resulting pose estimate distribution is then used to approximate the measurement covariance <em>R of the door observations.</em></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="simulation">Simulation<a href="#simulation" class="hash-link" aria-label="Direct link to Simulation" title="Direct link to Simulation">​</a></h3>
<p>Achieving championship-level performance in autonomous drone racing requires overcoming two challenges: imperfect perception and incomplete models of the system dynamics. In simulated, controlled experiments, we evaluate the robustness of our approach to these two challenges. To this end, we evaluate its performance on competition tasks when deployed in four different settings. In setting (1), we simulate a simple quadrotor model with access to ground-truth state observations. In setting (2), we replace the ground-truth state observations with noisy observations identified from real flights. These noisy observations are generated by sampling a realization from the residual observation model and are independent of the perception awareness of the deployed controller. Settings (3) and (4) share the observation model with the first two settings, respectively, but replace the simple dynamics model with a more accurate aerodynamic simulation [^43]. These four settings allow for a controlled evaluation of the sensitivity of the approach to dynamic changes and observation fidelity.</p>
<p>In each of the four settings, we benchmark our approach against the following baselines: zero-shot, domain randomization, and time-optimal. The zero-shot baseline represents a learning-based race policy trained using model-free RL [^35] that is deployed from the training domain to the test domain at zero shot. The training domain of this policy is equal to the experimental setting (1), i.e., idealized dynamics and ground truth observations. Domain randomization extends the learning policy of the zero-shot baseline by randomizing the observations and dynamic properties to improve robustness. The time-optimal baseline uses pre-computed time-optimal trajectories28 <sup><a aria-label="Reference 28" title="Foehn, P., Romero, A. and Scaramuzza, D. Time-optimal planning of waypoint flight for quadrotors. Robotics, vol. 6, p. eabh1221 (2021)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR28"><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">, tracked using an MPC controller. This approach shows the best performance </font></font></font></font></a></sup> <sup><a aria-label="参考文献 56" title="Pham, H. &amp; Pham, Q.-C. 一种基于可达性分析的时间最优路径参数化新方法。IEEE 机器人学报，34, 645–659 (2018)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR56"><font dir="auto"><font dir="auto"><font dir="auto">compared to other model-based time-optimal flight </font></font></font></a></sup> <sup><a aria-label="Reference 55" title="Ryou, G., Tal, E., and Karaman, S. Multi-fidelity black-box optimization for time-optimal quadrotor maneuvers. International Journal of Robotics Research 40, 1352–1369 (2021)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR55"><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">methods55,56</font></font></font></font></a></sup><sup><font dir="auto"><font dir="auto"><font dir="auto">.</font></font></font></sup> The dynamic models used for trajectory generation and the MPC controller match the simulated dynamics of the experimental setting (1).</p>
<p>Performance is measured by the fastest lap time, the average and minimum observed distances successfully passed through the gate, and the percentage of successfully completed tracks. The gate distance metric measures the distance between the drone and the nearest point on the gate as it passes through the gate plane. A larger gate distance indicates that the quadrotor passes closer to the center of the gate. A smaller gate distance increases speed but also increases the risk of collision or missing the gate. Any lap resulting in a collision will not be considered valid.</p>
<p>The results are summarized in Extended Data Table <a href="https://www.nature.com/articles/s41586-023-06419-4#Tab1" target="_blank" rel="noopener noreferrer">1c</a>. All methods successfully complete the task when deployed in idealized dynamics and ground-truth observations, with the time-optimal baseline producing the lowest lap time. When deployed in a setting with domain shift, the performance of all baselines collapses, both in dynamics and observations, and none of the three baselines completes a single lap. This performance degradation is observed for both learning-based and traditional methods. In contrast, our method, which features empirical models of dynamics and observation noise, achieves success in all deployment settings, with a slight increase in lap time.</p>
<p>The key to the success of our approach across various deployment regimes is that it uses empirical models of the dynamics and observation noise estimated from real data. Comparing methods that have access to such data with those that do not is not entirely fair. Therefore, we also benchmark the performance of all baseline methods when they have access to the same real data as our approach. Specifically, we compare performance in the experimental setting (2) where the dynamics model is idealized but the perception is noisy. All baseline methods provide predictions from the same Gaussian process model that we use to characterize the observation noise. The results are summarized in Extended Data Table <a href="https://www.nature.com/articles/s41586-023-06419-4#Tab1" target="_blank" rel="noopener noreferrer">1b</a>. All baseline methods benefit from more realistic observations, resulting in higher completion rates. However, our approach is the only one that can reliably complete the entire trajectory. In addition to the predictions from the observation noise model, our approach also accounts for model uncertainty. For an in-depth comparison of the performance of reinforcement learning and optimal control in controlled experiments, see Ref. [^57].</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="after-multiple-iterations">after multiple iterations<a href="#after-multiple-iterations" class="hash-link" aria-label="Direct link to after multiple iterations" title="Direct link to after multiple iterations">​</a></h3>
<p>We investigated the extent to which behavior changes during the iterations. Our analysis showed that subsequent fine-tuning operations resulted in negligible improvements in performance and changes in behavior (Extended Data Fig. <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig6" target="_blank" rel="noopener noreferrer">2</a> ).</p>
<p>Next, we provide more details about this investigation. We first list the fine-tuning steps to provide the necessary notation:</p>
<ol>
<li>Train policy 0 in simulation.</li>
<li>Deploy policy 0 in the real world. The policy is run on real data from a motion capture system.</li>
<li>Identify the residuals observed by policy 0 in the real world.</li>
<li>Policy 1 is trained by fine-tuning policy 0 on the identified residuals.</li>
<li>Deploy Strategy 1 in the real world. This strategy only works on airborne sensor measurements.</li>
<li>Identify the residuals observed by Strategy 1 in the real world.</li>
<li>Strategy 2 is trained by fine-tuning Strategy 1 on the identified residuals.</li>
</ol>
<p>After fine-tuning their respective residuals, we compared the performance of Policy 1 and Policy 2 in simulation. The results are shown in Extended Data Figure <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig6" target="_blank" rel="noopener noreferrer">2.</a> We observed a difference in distance from the gate center (a measure of policy safety) of 0.09 ± 0.08 meters. Furthermore, the difference in the time required to complete a lap was 0.02 ± 0.02 seconds. Note that this lap time difference is significantly smaller than the 0.16-second difference between Swift and a human pilot.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="drone-hardware">Drone hardware<a href="#drone-hardware" class="hash-link" aria-label="Direct link to Drone hardware" title="Direct link to Drone hardware">​</a></h3>
<p>The quadrotors used by human pilots and Swift have the same weight, shape, and propulsion. The platform design is based on the Agilicious framework58 <sup><a aria-label="Reference 58" title="Foehn, P. et al. Agilicious: An open-source and open-hardware agile quadrotor for vision-based flight. Robotics Science, 7, eabl6259 (2022)." href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR58"><font dir="auto"><font dir="auto"><font dir="auto"><font dir="auto">.</font></font></font></font></a></sup> Each vehicle weighs 870 grams and can produce a maximum static thrust of approximately 35 Newtons, resulting in a static thrust-to-weight ratio of 4.1. The base of each platform consists of an Armattan Chameleon 6-inch mainframe equipped with a T-Motor Velox 2306 motor and a 5-inch three-bladed propeller. The NVIDIA Jetson TX2 equipped with a Connect Tech Quasar carrier board provides the primary computing resources for the autonomous drones, featuring a six-core CPU running at 2 GHz and a dedicated GPU with 256 CUDA cores running at 1.3 GHz. While the forward pass of the door detection network is executed on the GPU, the competition policy is evaluated on the CPU, with one inference pass taking 8 milliseconds. The autonomous drone is equipped with an Intel RealSense tracking camera T265, which provides 100 Hz VIO estimates[^59] and transmits them via USB to an NVIDIA Jetson TX2. The manned drone does not have a Jetson computer or a RealSense camera, but is equipped with corresponding ballast. Control commands such as total thrust and body velocity generated by the human pilot or Swift are sent to a commercial flight controller running on a 216 MHz STM32 processor. The flight controller runs Betaflight, an open source flight control software[^45].</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="human-pilot">Human pilot<a href="#human-pilot" class="hash-link" aria-label="Direct link to Human pilot" title="Direct link to Human pilot">​</a></h3>
<p>The following quotes convey the impressions of the three human champions who competed against Swift.</p>
<p><strong>Alex Vanover</strong>:</p>
<ul>
<li>These races will be decided in the S-segment, the most challenging section of the course.</li>
<li>It was a fantastic race! I was so close to the autonomous drone that I could feel the rush of air as I tried to keep up.</li>
</ul>
<p><strong>Thomas Bitmata</strong>:</p>
<ul>
<li>The possibilities are endless, and this is the beginning of something that could change the world. On the other hand, I&#x27;m a race car driver, and I don&#x27;t want anything to be faster than me.</li>
<li>As you fly faster, you sacrifice accuracy for speed.</li>
<li>The potential for drones is exciting. Soon, AI-powered drones may even be used as training tools to help people understand their future possibilities.</li>
</ul>
<p><strong>Marvin Schepper</strong>:</p>
<ul>
<li>It’s a very different feeling racing against a machine because you know the machine won’t get tired.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="research">Research<a href="#research" class="hash-link" aria-label="Direct link to Research" title="Direct link to Research">​</a></h3>
<p>This study was conducted in accordance with the Declaration of Helsinki. According to the regulations of the University of Zurich, this study protocol did not require ethics committee review because no health-related data were collected. Participants provided written informed consent before participating in the study.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="data">Data<a href="#data" class="hash-link" aria-label="Direct link to Data" title="Direct link to Data">​</a></h2>
<p>All other data required to evaluate the conclusions of this paper are included in the paper or in the Extended Data. Motion capture recordings of the event and their analysis code are available in the file “racing_data.zip” from Zenodo at <a href="https://doi.org/10.5281/zenodo.7955278" target="_blank" rel="noopener noreferrer">https://doi.org/10.5281/zenodo.7955278</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="code">Code<a href="#code" class="hash-link" aria-label="Direct link to Code" title="Direct link to Code">​</a></h2>
<p>The Swift pseudocode detailing the training process and algorithm can be found in the file “pseudocode.zip” from Zenodo at <a href="https://doi.org/10.5281/zenodo.7955278" target="_blank" rel="noopener noreferrer">https://doi.org/10.5281/zenodo.7955278</a>. To prevent potential misuse, the full source code associated with this research will not be made public.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="more">More<a href="#more" class="hash-link" aria-label="Direct link to More" title="Direct link to More">​</a></h2>
<p>Paper address: <a href="https://www.nature.com/articles/s41586-023-06419-4" target="_blank" rel="noopener noreferrer">https://www.nature.com/articles/s41586-023-06419-4</a></p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/en/06_RL"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">9.6 强化学习</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/en/Algorithm_Development/RL/DifferentiablePhysicsDrone/DiffPhysDrone"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">DiffPhysDrone</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#abstract" class="table-of-contents__link toc-highlight">Abstract</a></li><li><a href="#main" class="table-of-contents__link toc-highlight">Main</a></li><li><a href="#swift" class="table-of-contents__link toc-highlight">Swift</a></li><li><a href="#results" class="table-of-contents__link toc-highlight">Results</a></li><li><a href="#discussion" class="table-of-contents__link toc-highlight">Discussion</a></li><li><a href="#methods" class="table-of-contents__link toc-highlight">Methods</a><ul><li><a href="#quadrotor" class="table-of-contents__link toc-highlight">Quadrotor</a></li><li><a href="#strategy" class="table-of-contents__link toc-highlight">Strategy</a></li><li><a href="#residual-model" class="table-of-contents__link toc-highlight">Residual Model</a></li><li><a href="#door" class="table-of-contents__link toc-highlight">Door</a></li><li><a href="#vio-drift" class="table-of-contents__link toc-highlight">VIO drift</a></li><li><a href="#simulation" class="table-of-contents__link toc-highlight">Simulation</a></li><li><a href="#after-multiple-iterations" class="table-of-contents__link toc-highlight">after multiple iterations</a></li><li><a href="#drone-hardware" class="table-of-contents__link toc-highlight">Drone hardware</a></li><li><a href="#human-pilot" class="table-of-contents__link toc-highlight">Human pilot</a></li><li><a href="#research" class="table-of-contents__link toc-highlight">Research</a></li></ul></li><li><a href="#data" class="table-of-contents__link toc-highlight">Data</a></li><li><a href="#code" class="table-of-contents__link toc-highlight">Code</a></li><li><a href="#more" class="table-of-contents__link toc-highlight">More</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Links</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.utmsys.org/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Homepage<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.utmsys.org/pages/contact/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Contact Us<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Follow Us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/utmsys" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.youtube.com/@utmsys/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Youtube<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.facebook.com/profile.php?id=61574010301135/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Facebook<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.instagram.com/utmsys/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Instagram<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 utmsys.</div></div></div></footer></div>
</body>
</html>