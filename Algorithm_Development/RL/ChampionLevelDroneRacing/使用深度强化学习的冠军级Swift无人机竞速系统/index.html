<!doctype html>
<html lang="zh" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Algorithm_Development/RL/ChampionLevelDroneRacing/使用深度强化学习的冠军级Swift无人机竞速系统" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">使用深度强化学习的冠军级Swift无人机竞速系统 | UTMSYS</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://wiki.utmsys.org/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://wiki.utmsys.org/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://wiki.utmsys.org/Algorithm_Development/RL/ChampionLevelDroneRacing/使用深度强化学习的冠军级Swift无人机竞速系统"><meta data-rh="true" property="og:locale" content="zh"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="zh"><meta data-rh="true" name="docsearch:language" content="zh"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="使用深度强化学习的冠军级Swift无人机竞速系统 | UTMSYS"><meta data-rh="true" name="description" content="摘要"><meta data-rh="true" property="og:description" content="摘要"><link data-rh="true" rel="icon" href="/img/logo.png"><link data-rh="true" rel="canonical" href="https://wiki.utmsys.org/Algorithm_Development/RL/ChampionLevelDroneRacing/使用深度强化学习的冠军级Swift无人机竞速系统"><link data-rh="true" rel="alternate" href="https://wiki.utmsys.org/en/Algorithm_Development/RL/ChampionLevelDroneRacing/使用深度强化学习的冠军级Swift无人机竞速系统" hreflang="en"><link data-rh="true" rel="alternate" href="https://wiki.utmsys.org/Algorithm_Development/RL/ChampionLevelDroneRacing/使用深度强化学习的冠军级Swift无人机竞速系统" hreflang="zh"><link data-rh="true" rel="alternate" href="https://wiki.utmsys.org/Algorithm_Development/RL/ChampionLevelDroneRacing/使用深度强化学习的冠军级Swift无人机竞速系统" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"9. 算法开发","item":"https://wiki.utmsys.org/09_Algorithm_Development"},{"@type":"ListItem","position":2,"name":"9.6 强化学习","item":"https://wiki.utmsys.org/06_RL"},{"@type":"ListItem","position":3,"name":"使用深度强化学习的冠军级Swift无人机竞速系统","item":"https://wiki.utmsys.org/Algorithm_Development/RL/ChampionLevelDroneRacing/使用深度强化学习的冠军级Swift无人机竞速系统"}]}</script><link rel="stylesheet" href="/assets/css/styles.fdfcd1c3.css">
<script src="/assets/js/runtime~main.7a42177b.js" defer="defer"></script>
<script src="/assets/js/main.a51edf4e.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav aria-label="主导航" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="切换导航栏" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">UTMSYS</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/UTMSYS介绍">Start</a><a href="https://www.utmsys.org/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Community<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/utmsys/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>简体中文</a><ul class="dropdown__menu"><li><a href="/en/Algorithm_Development/RL/ChampionLevelDroneRacing/使用深度强化学习的冠军级Swift无人机竞速系统" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en">English</a></li><li><a href="/Algorithm_Development/RL/ChampionLevelDroneRacing/使用深度强化学习的冠军级Swift无人机竞速系统" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="zh">简体中文</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="切换浅色/暗黑模式（当前为system mode）"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="搜索" aria-label="Search" class="navbar__search-input" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/UTMSYS介绍">UTMSYS ORG</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/01_Product_Overview">1. 产品概述</a><button aria-label="展开侧边栏分类 &#x27;1. 产品概述&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/02_Hardware_Connection">2. 硬件连接</a><button aria-label="展开侧边栏分类 &#x27;2. 硬件连接&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/03_Image_Flash">3. 镜像烧录</a><button aria-label="展开侧边栏分类 &#x27;3. 镜像烧录&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/04_Terminal_Access">4. 终端访问</a><button aria-label="展开侧边栏分类 &#x27;4. 终端访问&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/05_System_Config">5. 系统配置</a><button aria-label="展开侧边栏分类 &#x27;5. 系统配置&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/06_Software_Install">6. 软件安装</a><button aria-label="展开侧边栏分类 &#x27;6. 软件安装&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/07_Data_Communication">7. 数据通信</a><button aria-label="展开侧边栏分类 &#x27;7. 数据通信&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/08_Application_Development">8. 应用开发</a><button aria-label="展开侧边栏分类 &#x27;8. 应用开发&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/09_Algorithm_Development">9. 算法开发</a><button aria-label="折叠侧边栏分类 &#x27;9. 算法开发&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/01_CV">9.1 计算机视觉</a><button aria-label="展开侧边栏分类 &#x27;9.1 计算机视觉&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/02_MISSION">9.2 飞行任务</a><button aria-label="展开侧边栏分类 &#x27;9.2 飞行任务&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/03_PLANNER">9.3 路径规划</a><button aria-label="展开侧边栏分类 &#x27;9.3 路径规划&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/04_SLAM">9.4 定位建图</a><button aria-label="展开侧边栏分类 &#x27;9.4 定位建图&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/05_SIMULATOR">9.5 仿真模拟器</a><button aria-label="展开侧边栏分类 &#x27;9.5 仿真模拟器&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/06_RL">9.6 强化学习</a><button aria-label="折叠侧边栏分类 &#x27;9.6 强化学习&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/Algorithm_Development/RL/ChampionLevelDroneRacing/使用深度强化学习的冠军级Swift无人机竞速系统">ChampionLevelDroneRacing</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Algorithm_Development/RL/ChampionLevelDroneRacing/使用深度强化学习的冠军级Swift无人机竞速系统">使用深度强化学习的冠军级Swift无人机竞速系统</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/Algorithm_Development/RL/DifferentiablePhysicsDrone/通过可微分物理学习基于视觉的敏捷飞行">DifferentiablePhysicsDrone</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/Algorithm_Development/RL/NavRL/学习动态环境中的安全飞行">NavRL</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/07_VLM">9.7 视觉语言模型</a><button aria-label="展开侧边栏分类 &#x27;9.7 视觉语言模型&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/08_HPC">9.8 高性能计算</a><button aria-label="展开侧边栏分类 &#x27;9.8 高性能计算&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/10_Debug_Commands">10. 调试命令</a><button aria-label="展开侧边栏分类 &#x27;10. 调试命令&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/11_Concepts">11. 相关概念</a><button aria-label="展开侧边栏分类 &#x27;11. 相关概念&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/12_FAQ">12. 常见问题</a><button aria-label="展开侧边栏分类 &#x27;12. 常见问题&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/13_Release">13. 发布日志</a><button aria-label="展开侧边栏分类 &#x27;13. 发布日志&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/09_Algorithm_Development"><span>9. 算法开发</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/06_RL"><span>9.6 强化学习</span></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">ChampionLevelDroneRacing</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">使用深度强化学习的冠军级Swift无人机竞速系统</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>Champion-level drone racing using deep reinforcement learning - Nature</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="摘要">摘要<a href="#摘要" class="hash-link" aria-label="摘要的直接链接" title="摘要的直接链接">​</a></h2>
<p>第一人称视角 (FPV) 无人机竞速是一项电视转播的运动，专业选手驾驶高速飞机穿越 3D 赛道。每位飞行员通过无人机的视角通过机载摄像头传输的视频观察周围环境。要达到专业飞行员的自主无人 机水平是一项挑战，因为机器人需要在极限范围内飞行，同时仅通过机载传感器 [^1] 估计其在赛道上的速度和位置。这里我们介绍 Swift，这是一个可以与人类世界冠军水平的实体车辆竞赛的自主系统。该系统将模拟中的深度强化学习 (RL) 与现实世界中收集的数据相结合。Swift 在现实世界的正面交锋中与三位人类冠军展开竞争，其中包括两个国际联赛的世界冠军。Swift 赢得了与每位人类冠军的几场比赛，并创下了最快的比赛时间记录。这项工作代表了移动机器人和机器智能的一个里程碑 [^2] ，这可能会启发在其他物理系统中部署基于混合学习的解决方案。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="主要的">主要的<a href="#主要的" class="hash-link" aria-label="主要的的直接链接" title="主要的的直接链接">​</a></h2>
<p>深度强化学习 [^3] 推动了人工智能的一些最新进展。使用深度强化学习训练的策略在复杂的竞技游戏中表现优于人类，包括雅达利 <sup><font dir="auto">4、5、6 </font></sup> <sup><font dir="auto">、</font></sup> <sup><a title="Schrittwieser, J. 等人。通过学习模型进行规划，掌握雅达利、围棋、国际象棋和将棋。《自然》588, 604–609 (2020)。" href="https://www.nature.com/articles/#ref-CR5"><font dir="auto">围棋</font></a></sup> <sup><a aria-label="参考文献 6" title="Ecoffet, A., Huizinga, J., Lehman, J., Stanley, KO &amp; Clune, J. 先回归，再探索。《自然》590, 580–586 (2021)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR6"><font dir="auto">5、7、8、9 </font></a></sup> <sup><a title="Mnih, V. 等人。通过深度强化学习实现人类水平的控制。《自然》518, 529–533 (2015)。" href="https://www.nature.com/articles/#ref-CR4"><font dir="auto"><font dir="auto">、</font></font></a> <font dir="auto"><font dir="auto">国际</font></font></sup> 象棋 <sup><a aria-label="参考文献 5" title="Schrittwieser, J. 等人。通过学习模型进行规划，掌握雅达利、围棋、国际象棋和将棋。《自然》588, 604–609 (2020)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR5"><font dir="auto"><font dir="auto">5、9</font></font></a></sup> <sup><font dir="auto">、</font></sup> <sup><a title="Silver, D. 等人。《利用深度神经网络和树形搜索掌握围棋游戏》。《自然》529, 484–489 (2016)。" href="https://www.nature.com/articles/#ref-CR7"><font dir="auto">星际</font></a></sup> 争霸 [^10] <sup><font dir="auto">、</font></sup> <sup><a title="Silver, D. 等人。无需人类知识即可掌握围棋游戏。《自然》550, 354–359 (2017)。" href="https://www.nature.com/articles/#ref-CR8"><font dir="auto">Dota</font></a></sup> 2 <sup><a aria-label="参考文献 5" title="Schrittwieser, J. 等人。通过学习模型进行规划，掌握雅达利、围棋、国际象棋和将棋。《自然》588, 604–609 (2020)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR5"><font dir="auto"><font dir="auto">（</font></font></a> <a aria-label="参考文献 9" title="Silver, D. 等人。一种通过自我对弈掌握国际象棋、将棋和围棋的通用强化学习算法。Science 362, 1140–1144 (2018)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR9"><font dir="auto"><font dir="auto">参考</font></font></a></sup> 文献  [^11] <sup><font dir="auto">）</font></sup> <sup><font dir="auto">和</font></sup> Gran Turismo <sup><a aria-label="参考文献 12" title="Fuchs, F.、Song, Y.、Kaufmann, E.、Scaramuzza, D. 和 Dürr, P. 利用深度强化学习在 Gran Turismo Sport 中实现超人表现。IEEE Robot. Autom. Lett. 6, 4257–4264 (2021)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR12"><font dir="auto">12、13 。这些令人印象深刻</font></a></sup> <sup><a aria-label="参考文献 11" title="Berner, C. 等人。基于大规模深度强化学习的 Dota 2 。预印本链接：https://arxiv.org/abs/1912.06680 (2019)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR11"><font dir="auto"><font dir="auto">的机器智能能力展示主要局限于模拟和</font></font></a></sup> <sup><a aria-label="参考文献 13" title="Wurman, PR 等人。利用深度强化学习超越 Gran Turismo 赛车冠军车手。《自然》602, 223–228 (2022)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR13"><font dir="auto">棋盘</font></a></sup> 游戏环境，这些环境支持在精确复制测试条件中进行策略搜索。 克服这一限制并在体育竞赛中展现冠军级表现是自主移动机器人和人工智能领域长期 <sup><a title="Spielberg, NA, Brown, M., Kapania, NR, Kegelman, JC &amp; Gerdes, JC. 用于高性能自动驾驶的神经网络车辆模型。《机器人科学》，第4卷，eaaw1975期（2019）。" href="https://www.nature.com/articles/#ref-CR15"><font dir="auto">存在</font></a></sup> <sup><a aria-label="参考文献 16" title="Won, D.-O.、Müller, K.-R. 和 Lee, S.-W. 自适应深度强化学习框架使冰壶机器人在现实条件下具有类似人类的表现。《机器人科学》5, eabb9764 (2020)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR16"><font dir="auto">的</font></a></sup> <sup><font dir="auto">问题</font></sup> <sup><a title="Funke, J. 等人在 2012 IEEE 智能汽车研讨会论文集 541–547 中（IEEE，2012 年）。" href="https://www.nature.com/articles/#ref-CR14"><font dir="auto">14、15、16</font></a></sup> <sup><font dir="auto">。</font></sup></p>
<p>FPV 无人机竞赛是一项电视转播的运动，其中训练有素的人类飞行员通过高速灵活的机动将飞行器推向物理极限（图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig1" target="_blank" rel="noopener noreferrer">1a</a> ）。FPV 竞赛中使用的飞行器是四轴飞行器，它们是有史以来最灵活的机器之一（图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig1" target="_blank" rel="noopener noreferrer">1b</a> ）。在比赛期间，飞行器施加的力量超过其自身重量的五倍或更多，速度超过 100 km h <sup><font dir="auto"><font dir="auto">-1</font></font></sup> ，加速度是重力的几倍，即使在密闭空间内也是如此。每架飞行器都由一名人类飞行员远程控制，飞行员戴着耳机，耳机上显示着机载摄像头的视频流，营造出身临其境的“第一人称视角”体验（图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig1" target="_blank" rel="noopener noreferrer">1c</a> ）。</p>
<p><img decoding="async" loading="lazy" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-023-06419-4/MediaObjects/41586_2023_6419_Fig1_HTML.png?as=webp" alt="图1" class="img_ev3q"></p>
<p>图 1：无人机竞赛。</p>
<p>创建达到人类飞行员表现的自主系统的尝试可以追溯到 2016 年的第一届自主无人机竞赛（参考文献  [^17] <sup><a aria-label="参考文献 17" title="Moon, H., Sun, Y., Baltes, J. 和 Kim, SJ，《IROS 2016 竞赛》。IEEE Robot. Autom. Mag. 24, 20–29 (2017)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR17"><font dir="auto"><font dir="auto">）</font></font></a></sup> 。随后出现了一系列创新，包括使用深度网络识别下一个门位置 <sup><a aria-label="参考文献 20" title="Zhang, D. 和 Doyle, DD，载于 Proc. 2020 IEEE 航空航天会议，1-11（IEEE，2020 年）。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR20"><font dir="auto">18、19、20</font></a></sup> <sup><font dir="auto">、</font></sup> <sup><a title="Jung, S., Hwang, S., Shin, H. &amp; Shim, DH, 基于深度学习的室内自主无人机竞速感知、制导和导航。IEEE Robot. Autom. Lett. 3, 2539–2544 (2018)。" href="https://www.nature.com/articles/#ref-CR18"><font dir="auto"><font dir="auto">将</font></font></a> <font dir="auto"><font dir="auto">  竞赛</font></font></sup> <sup><a aria-label="参考文献 24" title="Li, S., van der Horst, E., Duernay, P., De Wagter, C. &amp; de Croon, GC. 视觉模型预测定位，实现72g无人机高效自主竞速。《J. Field Robot》杂志，第37卷，第667–692页（2020年）。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR24"><font dir="auto">策略</font></a></sup> 从模拟转移到现实 <sup><font dir="auto">21、22</font></sup> <sup><a aria-label="参考文献 21" title="Loquercio, A. 等人。深度无人机竞速：通过领域随机化从模拟到现实。IEEE 机器人学报，36, 1–14 (2019)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR21"><font dir="auto"><font dir="auto">以及</font></font></a></sup> 考虑感知中的不确定性 <sup><font dir="auto">23、24。2019</font></sup> <sup><a aria-label="参考文献 23" title="Kaufmann，E.等人在2019年国际机器人与自动化会议（ICRA）第690–696期（IEEE，2019年）中。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR23"><font dir="auto"><font dir="auto">年</font></font></a></sup> AlphaPilot 自主无人机竞赛展示了该领域的一些最佳研究 <sup><a aria-label="参考文献 25" title="人工智能正在驾驶无人机（速度非常非常慢）。https://www.nytimes.com/2019/03/26/technology/alphapilot-ai-drone-racing.html (2019)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR25"><font dir="auto"><font dir="auto">25。</font></font></a></sup> 然而，前两支队伍仍然花费了几乎两倍于专业人类飞行员完成赛道的时间 <sup><a aria-label="参考文献 22" title="Loquercio, A. 等人。《学习野外高速飞行》。《机器人科学》，第 6 卷，eabg5810 页（2021 年）。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR22"><font dir="auto">26、27 </font></a></sup> <sup><a aria-label="参考文献 27" title="Wagter, CD, Paredes-Vallé, F., Sheth, N. 和 de Croon, G. 2019 年人工智能机器人竞 赛获胜作品背后的感知、状态估计和控制。《野外机器人》。2, 1263–1290 (2022)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR27"><font dir="auto">。</font></a></sup> <sup><a aria-label="参考文献 26" title="Foehn, P. 等人。AlphaPilot：自主无人机竞速。Auton. Robots 46, 307–320 (2021)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR26"><font dir="auto"><font dir="auto">最近</font></font></a></sup> ，自主系统已经开始达到人类专家的表现 <sup><a title="Foehn, P.、Romero, A. 和 Scaramuzza, D. 四旋翼航点飞行的时间最优规划。《机器人科学》，第 6 卷，eabh1221 页（2021 年）。" href="https://www.nature.com/articles/#ref-CR28"><font dir="auto"><font dir="auto">28、29、30</font></font></a></sup> <sup><font dir="auto">。然而，这些</font></sup> <sup><font dir="auto">工作依赖于外部运动捕捉系统提供的近乎</font></sup> <sup><font dir="auto">完美的状态估计。这使得与人类飞行员</font></sup> <sup><a title="Romero, A.、Sun, S.、Foehn, P. 和 Scaramuzza, D. 时间最优四旋翼飞行的模型预测轮廓控制。IEEE 机器人学报，38, 3340–3356 (2022)。" href="https://www.nature.com/articles/#ref-CR29"><font dir="auto">的比较</font></a></sup> <sup><a aria-label="参考文献 30" title="Sun, S., Romero, A., Foehn, P., Kaufmann, E. &amp; Scaramuzza, D. 非线性MPC与基于差分平坦度的四旋翼敏捷飞行控制比较研究。IEEE机器人学报，38, 3357–3373 (2021)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR30"><font dir="auto">不</font></a></sup> 公平，因为人类只能从无人机上获取机载观测数据。</p>
<p>本文将介绍 Swift，这是一个自主飞行系统，它仅使用机载传感器和计算能力，就能驾驶四旋翼飞行器与人类世界冠军进行比赛。Swift 由两个关键模块组成：(1) 感知系统，将高维视觉和惯性信息转换为低维表示；(2) 控制策略，接  收感知系统生成的低维表示并生成控制命令。</p>
<p>控制策略由前馈神经网络表示，并在模拟环境中使用无模型的在线策略深度强化学习 [^31] 进行训练。为了弥合模拟环境与物理世界在感知和动态方面的差异，我们利用了根据物理系统收集的数据估计的非参数经验噪声模型。这些经验噪声模型已被证明对于将控制策略从模拟环境成功迁移到现实环境至关重要。</p>
<p>我们在由专业无人机竞速飞手设计的实体赛道上对 Swift 进行了评估（图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig1" target="_blank" rel="noopener noreferrer">1a</a> ）。赛道由七个方形门组成，体积为 30 × 30 × 8 米，形成一圈长 75 米的赛道。Swift 在这条赛道上与三位人类冠军展开角逐：2019 年无人机竞速联盟世界冠军 Alex Vanover、两届 MultiGP 国际公开赛世界杯冠军 Thomas Bitmatta 和三届瑞士全国冠军 Marvin Schaepper。Swift 和人类飞手使用的四旋翼飞行器具有相同的重量、形状和推进力。它们与国际比赛中使用的无人机类似。</p>
<p>人类飞行员在赛道上进行了一周的练习。练习结束后，每位飞行员将与Swift进行几场正面交锋（图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig1" target="_blank" rel="noopener noreferrer">1a、b</a> ）。在每场正面交锋中，两架无人机（一架由人类飞行员控制，一架由Swift控制）从领奖台上起跑。比赛由声音信号开始。率先完成三圈完整赛道飞行，并每圈按正确顺序通过所有门的无人机将赢得比赛。</p>
<p>Swift 在与每位人类飞行员的比赛中都取得了胜利，并创造了赛事中最快记录。据我们所知，这是自主移动机器人首次在现实世界的竞技体育中取得世界冠军级别的成绩。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="swift-系统">Swift 系统<a href="#swift-系统" class="hash-link" aria-label="Swift 系统的直接链接" title="Swift 系统的直接链接">​</a></h2>
<p>Swift 结合了基于学习的算法和传统算法，将机载传感器读数映射到控制命令。该映射包含两部分：(1) 观察策略，将高维视觉和惯性信息提炼为特定于任务的低维编码；(2) 控制策略，将编码转换为无人机的指令。系统示意图如图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig2" target="_blank" rel="noopener noreferrer">2</a> 所示。</p>
<p><img decoding="async" loading="lazy" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-023-06419-4/MediaObjects/41586_2023_6419_Fig2_HTML.png?as=webp" alt="图2" class="img_ev3q"></p>
<p>图 2：Swift 系统。</p>
<p>观察策略由视觉惯性估计器 <sup><a aria-label="参考文献 32" title="Scaramuzza, D. 和Zhang, Z. 机器人百科全书（Ang, M.、Khatib, O. 和 Siciliano, B. 编辑）1–9（Springer，2019 年）。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR32"><font dir="auto"><font dir="auto">32、33</font></font></a> <font dir="auto"><font dir="auto">组成，它们</font></font></sup> 与门检测器 <sup><a aria-label="参考文献 26" title="Foehn, P. 等人。AlphaPilot：自主无人机竞速。Auton. Robots 46, 307–320 (2021)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR26"><font dir="auto"><font dir="auto">26协同运行，后者是一个卷积神经网络，用于</font></font></a></sup> <sup><a aria-label="参考文献 33" title="Huang, G. 在 2019 年国际机器人与自动化会议 (ICRA) 9572–9582 号论文集 (IEEE, 2019) 中。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR33"><font dir="auto">检测</font></a></sup> 机载图像中的比赛门。检测到的门随后用于估计无人机沿赛道的全局位置和方向。这由摄像机后方交会算法 [^34] 结合赛道地图完成。然后，通过卡尔曼滤波器将从门检测器获得的全局姿态估计值与视觉惯性估计器的估计值相结合，从而更准确地表征机器人的状态。控制策略由双层感知器表示，它将卡尔曼滤波器的输出映射到无人机的控制命令。该策略在模拟中使用基于策略的无模型深度强化学习 <sup><a aria-label="参考文献 31" title="Schulman, J.、Wolski, F.、Dhariwal, P.、Radford, A. 和 Klimov, O. 近端策略优化算法。预印本链接：https://arxiv.org/abs/1707.06347 (2017)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR31"><font dir="auto"><font dir="auto">31进行训练。在训练过程中，该策略最大化将接近下一个比赛门</font></font></a></sup> [^35] 的奖励 与将下一个门保持在摄像机视野范围内的感知目标相结合的奖励。看到下一个门会得到奖励，因为它增加了姿势估计的准确性。</p>
<p>如果无法消除模拟与现实之间的差异，仅通过模拟来优化策略会导致物理硬件性能不佳。这些差异主要由两个因素造成：(1) 模拟动态与实际动态之间的差异；(2) 观察策略在获取真实传感数据时对机器人状态的估计存在噪声。我们通过在现实世界中收集少量数据并利用这些数据来提高模拟器的真实度，从而缓解这些差异。</p>
<p>具体来说，当无人机在赛道上行驶时，我们会记录机器人的机载传感器观测结果以及来自运动捕捉系统的高精度姿态估计。在此数据收集阶段，机器人由经过模拟训练的策略控制，该策略对运动捕捉系统提供的姿态估计进行操作。记录的数据可以识别通过赛道观察到的感知和动态的特征故障模式。这些感知失败和未建模动态的复杂性取决于环境、平台、赛道和传感器。感知和动态残差分别使用高斯过程 [^36] 和 <em>k</em> 最近邻回归建模。这种选择的动机是我们通过经验发现感知残差是随机的，而动态残差在很大程度上是确定性的（扩展数据图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig5" target="_blank" rel="noopener noreferrer">1</a> ）。这些残差模型被集成到模拟中，并且在这个增强模拟中对赛车策略进行了微调。这种方法与参考文献中用于模拟到现实转移的经验执行器模型相关。  [^37] 但进一步结合了感知系统的经验建模，并考虑了平台状态估计的随机性。</p>
<p>我们在扩展数据中报告的受控实验中消除了 Swift 的每个组件。此外，我们还将其与使用传统方法（包括轨迹规划和模型预测控制 (MPC)）解决自主无人机竞赛任务的最新研究进行了比较。尽管此类方法在理想条件下（例如简化的动力学和对机器人状态的完美了解）实现了与我们的方法相当甚至更优的性能，但当它们的假设被违反时，它们的性能就会崩溃。我们发现依赖于预先计算路径 <sup><a aria-label="参考文献 28" title="Foehn, P.、Romero, A. 和 Scaramuzza, D. 四旋翼航点飞行的时间最优规划。《机器人科学》，第 6 卷，eabh1221 页（2021 年）。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR28"><font dir="auto"><font dir="auto">28、29 的</font></font></a> <a aria-label="参考文献 29" title="Romero, A.、Sun, S.、Foehn, P. 和 Scaramuzza, D. 时间最优四旋翼飞行的模型预测轮廓控制。IEEE 机器人学报，38, 3340–3356 (2022)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR29"><font dir="auto"><font dir="auto">方法</font></font></a></sup> <sup><font dir="auto">对嘈杂的感知和动态特别敏感。即使配备了来自运动捕捉系统的高精度状态估计，传统方法也</font></sup> 无法实现与 Swift 或人类世界冠军相比具有竞争力的单圈时间。扩展数据中提供了详细的分析。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="结果">结果<a href="#结果" class="hash-link" aria-label="结果的直接链接" title="结果的直接链接">​</a></h2>
<p>无人机比赛在由外部世界级FPV飞手设计的赛道上进行。赛道上充满了各种特色动作和挑战，例如Split-S（图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig1" target="_blank" rel="noopener noreferrer">1a</a> （右上角）和 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig4" target="_blank" rel="noopener noreferrer">图4d</a> ）。即使发生碰撞，飞手也可以继续比赛，前提是他们的无人机仍然能够飞行。如果两架无人机都发生碰撞并无法完成比赛，则在赛道上行驶更远的无人机将获胜。</p>
<p><a href="https://www.nature.com/articles/s41586-023-06419-4#Fig3" target="_blank" rel="noopener noreferrer">如图3b</a> 所示 ，Swift 在与 A. Vanover 的 9 场比赛中赢了 5 场，在与 T. Bitmatta 的 7 场比赛中赢了 4 场，在与 M. Schaepper 的 9 场比赛中赢了 6 场。Swift 记录的 10 次失败中，40% 是由于与对手相撞，40% 是由于与大门相撞，20% 是由于无人机速度慢于人类飞行员。总体而言，Swift 在与每位人类飞行员的比赛中都取得了胜利。Swift 还创造了最快的比赛时间，比人类飞行员（A. Vanover）的最佳时间领先半秒。</p>
<p><img decoding="async" loading="lazy" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-023-06419-4/MediaObjects/41586_2023_6419_Fig3_HTML.png?as=webp" alt="图3" class="img_ev3q"></p>
<p><strong>图 3：结果。</strong></p>
<p>图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig4" target="_blank" rel="noopener noreferrer">4</a> 和扩展数据表 <a href="https://www.nature.com/articles/s41586-023-06419-4#Tab1" target="_blank" rel="noopener noreferrer">1d</a> 对 Swift 和每位人类飞行员飞过的最快圈速进行了分析。尽管 Swift 的整体速度比所有人类飞行员都快，但它在赛道的所有单独路段上的速度并不快（扩展数据表 <a href="https://www.nature.com/articles/s41586-023-06419-4#Tab1" target="_blank" rel="noopener noreferrer">1</a> ）。Swift 在起跑和急转弯（如分叉 S）时始终速度更快。起跑时，Swift 的反应时间较短，平均比人类飞行员早 120 毫秒起跑。此外，它加速更快，在进入第一个门时达到更高的速度（扩展数据表 <a href="https://www.nature.com/articles/s41586-023-06419-4#Tab1" target="_blank" rel="noopener noreferrer">1d</a> ，第 1 段）。在急转弯处，如图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig4" target="_blank" rel="noopener noreferrer">4c、d所示，Swift 可以找到更紧凑的动作。有一种假设是，Swift 比人类飞行员在更长的时间尺度上优化轨迹。众所周知，无模型 RL 可以通过价值函数</a> [^38] 优化长期奖励 。相反，人类飞行员在更短的时间尺度上规划他们的运动，最多提前一个门 [^39] 。例如在分段 S 中（图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig4" target="_blank" rel="noopener noreferrer">4b、d</a> ）这一点很明显，人类飞行员在机动开始和结束时速度更快，但整体速度较慢（扩展数据表 <a href="https://www.nature.com/articles/s41586-023-06419-4#Tab1" target="_blank" rel="noopener noreferrer">1d</a> ，第 3 段）。此外，人类飞行员比 Swift 更早地将飞机调整至面向下一个登机口（图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig4" target="_blank" rel="noopener noreferrer">4c、d</a> ）。我们认为人类飞行员习惯于将即将到来的登机口保持在视野中，而 Swift 已经学会了依靠其他线索执行某些机动，例如惯性数据和针对周围环境特征的视觉里程计。总体而言，在整个赛道上平均而言，自主无人机实现了最高平均速度，找到了最短的赛道，并设法在整个比赛过程中将飞机保持在更接近其驱动极限的位置，如平均推力和功率所示（扩展数据表 <a href="https://www.nature.com/articles/s41586-023-06419-4#Tab1" target="_blank" rel="noopener noreferrer">1d</a> ）。</p>
<p><img decoding="async" loading="lazy" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-023-06419-4/MediaObjects/41586_2023_6419_Fig4_HTML.png?as=webp" alt="图4" class="img_ev3q"></p>
<p><strong>图 4：分析。</strong></p>
<p>我们还比较了 Swift 和人类冠军在计时赛中的表现（图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig3" target="_blank" rel="noopener noreferrer">3a</a> ）。在计时赛中，一名飞行员在赛道上比赛，圈数由飞行员自行决定。我们积累了练习周和比赛的计时赛数据，包括训练运行（图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig3" target="_blank" rel="noopener noreferrer">3a</a> ，彩色）和比赛条件下的飞行圈数（图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig3" target="_blank" rel="noopener noreferrer">3a</a> ，黑色）。对于每个参赛者，我们使用 300 多圈来计算统计数据。自主无人机更持续地追求更快的圈速，表现出更低的平均值和方差。相反，人类飞行员会根据每一圈来决定是否追求速度，无论是在训练期间还是在比赛中，都会产生更高的圈速平均值和方差。调整飞行策略的能力使人类飞行员在发现自己明显领先时可以保持较慢的速度，以降低坠机风险。自主无人机不知道它的对手，无论如何都会争取最快的预期完成时间，当领先时可能会冒太大的风险，而当落后 <sup><a aria-label="参考文献 40" title="Spica, R., Cristofalo, E., Wang, Z., Montijano, E. 和 Schwager, M. 用于自主双人无人机竞速的实时博弈论规划器。IEEE 机器人学报，36，1389–1403 (2020)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR40"><font dir="auto"><font dir="auto">40 时</font></font></a></sup> 则风险太小。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="讨论">讨论<a href="#讨论" class="hash-link" aria-label="讨论的直接链接" title="讨论的直接链接">​</a></h2>
<p>FPV 无人机竞赛需要根据来自物理环境的嘈杂和不完整的感官输入进行实时决策。我们提出了一种自主物理系统，可以在这项运动中达到冠军级别的表现，达到甚至有时超过人类世界冠军的表现。我们的系统比人类飞行员具有某些结构优势。首先，它利用来自机载惯性测量单元 <sup><a aria-label="参考文献 32" title="Scaramuzza, D. 和Zhang, Z. 机器人百科全书（Ang, M.、Khatib, O. 和 Siciliano, B. 编辑）1–9（Springer，2019 年）。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR32"><font dir="auto"><font dir="auto">32 的</font></font></a></sup> 惯性数据。这类似于人类的前庭系统 [^41] ，人类飞行员并不使用该系统，因为他们并不在飞机上，也感觉不到作用在飞机上的加速度。其次，我们的系统受益于较低的感觉运动延迟（Swift 为 40 毫秒，而专业人类飞行员的平均延迟为 220 毫秒 [^39] ）。另一方面，Swift 使用的摄像头的有限刷新率（30 Hz）可以被认为是人类飞行员的结构优势，他们的摄像头刷新率是人类飞行员的四倍（120 Hz），从而提高了他们的反应时间 [^42] 。</p>
<p>人类飞行员具有令人印象深刻的稳健性：他们可以在全速坠毁时继续飞行并完成赛道——如果硬件仍然正常工作的话。Swift 并没有接受过坠毁后恢复的训练。人类飞行员对环境条件的变化（例如照明）也具有很强的稳健性，因为环境条件的变化会显著改变赛道的外观。相比之下，Swift 的感知系统假设环境的外观与训练期间观察到的外观一致。如果不满足这个假设，系统就会失败。可以通过在多种条件下训练门检测器和残差观测模型来提供对外观变化的稳健性。解决这些限制可以使所提出的方法应用于自主无人机竞 赛中，在这种竞赛中，对环境和无人机的访问受到限制 [^25] 。</p>
<p>尽管仍存在诸多限制，且未来仍需进一步研究，但自主移动机器人在热门体育运动中取得世界冠军级别的成绩，无疑是机器人技术和机器智能领域的一个里程碑。这项工作或将启发基于混合学习的解决方案在其他物理系统（例如自主地面车辆、飞行器和个人机器人）中得到广泛应用。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="方法">方法<a href="#方法" class="hash-link" aria-label="方法的直接链接" title="方法的直接链接">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="四旋翼飞行器模拟">四旋翼飞行器模拟<a href="#四旋翼飞行器模拟" class="hash-link" aria-label="四旋翼飞行器模拟的直接链接" title="四旋翼飞行器模拟的直接链接">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="四旋翼飞行器动力学">四旋翼飞行器动力学<a href="#四旋翼飞行器动力学" class="hash-link" aria-label="四旋翼飞行器动力学的直接链接" title="四旋翼飞行器动力学的直接链接">​</a></h4>
<p>为了实现大规模训练，我们使用了四旋翼飞行器动力学的高保真模拟。本节简要介绍该模拟过程。飞行器的动力学可以表示为</p>
<p>$x˙=[p˙WBq˙WBv˙Wω˙BΩ˙]=[vWqWB⋅[0ωB/2]1m(qWB⊙(fprop+faero))+gWJ−1(τprop+τmot+τaero+τiner)1kmot(Ωss−Ω)],$</p>
<p>$fprop=∑ifi,τprop=∑iτi+rP,i×fi,$</p>
<p>（2）</p>
<p>$τmot=Jm+p∑iζiΩ˙i,τiner=−ωB×JωB$</p>
<p>（3）</p>
<p>$fi(Ωi)=[00cl⋅Ωi2]⊤,τi(Ωi)=[00cd⋅Ωi2]⊤$</p>
<p>（4）</p>
<p>其中 <em>c</em> <sub><font dir="auto"><font dir="auto">l</font></font></sub> 和 <em>c</em> <sub><font dir="auto"><font dir="auto">d</font></font></sub> 分别表示螺旋桨升力系数和阻力系数。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="空气动力和扭矩">空气动力和扭矩<a href="#空气动力和 扭矩" class="hash-link" aria-label="空气动力和扭矩的直接链接" title="空气动力和扭矩的直接链接">​</a></h4>
<p>$fx∼vx+vx|vx|+Ω2¯+vxΩ2¯fy∼vy+vy|vy|+Ω2¯+vyΩ2¯fz∼vz+vz|vz|+vxy+vxy2+vxyΩ2¯+vzΩ2¯+vxyvzΩ2¯τx∼vy+vy|vy|+Ω2¯+vyΩ2¯+vy|vy|Ω2¯τy∼vx+vx|vx|+Ω2¯+vxΩ2¯+vx|vx|Ω2¯τz∼vx+vy$</p>
<p>然后，我们会从真实飞行数据中识别相应的系数，并使用运动捕捉技术提供地面实况力和扭矩测量值。我们使用来自赛道的数据，使动力学模型能够拟合赛道。这类似于人类飞行员在比赛前几天或几周在特定赛道上进行的训练。在我们的案例中，人类飞行员会在比赛前在同一赛道上进行为期一周的练习。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="betaflight-低级控制器">Betaflight 低级控制器<a href="#betaflight-低级控制器" class="hash-link" aria-label="Betaflight 低级控制器的直接链接" title="Betaflight 低级控制器的直接链接">​</a></h4>
<p>为了控制四旋翼飞行器，神经网络输出总推力和机身速率。众所周知，这种控制信号兼具高灵活性和良好的鲁棒性，易于从模拟转换到现实 [^44] 。然后，预测的总推力和机身速率由机载低级控制器处理，该控制器计算各个电机指令，随后通过控制电机的电子速度控制器 (ESC) 将这些指令转换成模拟电压信号。在实体飞行器上，这种低级比例-积分-微分 (PID) 控制器和 ESC 是使用开源 Betaflight 和 BLHeli32 固件 [^45] 实现的。在模拟中，我们使用低级控制器和电机速度控制器的精确模型。</p>
<p>由于 Betaflight PID 控制器已针对载人飞行进行了优化，因此它表现出一些特性，而仿真能够准确捕捉这些特性：D 项的参考值始终为零（纯阻尼），I 项在油门关闭时重置，并且在电机推力饱和的情况下，机身速率控制被赋予优先级（按比例缩小所有电机信号以避免饱和）。用于仿真的控制器增益已从 Betaflight 控制器内部状态的详细日志中识别出来。仿真能够预测各个电机指令，误差小于 1%。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="电池模型和esc">电池模型和ESC<a href="#电池模型和esc" class="hash-link" aria-label="电池模型和ESC的直接链接" title="电池模型和ESC的直接链接">​</a></h4>
<p>底层控制器将各个电机指令转换为脉冲宽度调制 (PWM) 信号，并将其发送至控制电机的 ESC。由于 ESC 不对电机转速进行闭环控制，因此 给定 PWM 电机指令 cmd <sub><i><font dir="auto">i时，稳态电机转速 Ω </font></i></sub> <sub><i><font dir="auto"><font dir="auto">i</font></font></i><font dir="auto"><font dir="auto">,ss是电池电压的函数。因此，我们的仿真使用灰盒电池模型</font></font></sub> [^46] 对电池电压进行建模， 该模型基于瞬时功耗 <em>P</em> <sub><font dir="auto">mot</font></sub> 来模拟电压：</p>
<p>$Pmot=cdΩ3η$</p>
<p>（5）</p>
<p><sub><font dir="auto">然后，</font></sub> 电池模型 [^46] 根据该功率需求模拟电池电压。给定电池电压 <em>Ubat</em> 和单个电机指令 <em>ucmd</em> <sub><font dir="auto">, </font></sub> <sub><i><font dir="auto">i</font></i></sub> ，我们使用映射（同样省略了与每个加数相乘的系数）</p>
<p>$Ωi,ss∼1+Ubat+ucmd,i+ucmd,i+Ubatucmd,i$</p>
<p>（6）</p>
<p><a href="https://www.nature.com/articles/s41586-023-06419-4#Equ1" target="_blank" rel="noopener noreferrer">计算公式 ( 1</a> )中动力学仿真所需的 相应稳态电机转速 Ω <sub><i><font dir="auto"><font dir="auto">i</font></font></i><font dir="auto"><font dir="auto">,ss</font></font></sub> 。这些系数已从包含所有相关量测量值的 Betaflight 日志中识别出来。结合低级控制器模型，这使得模拟器能够将总推力和机体速率形式的动作正确地转换为 公式 ( <a href="https://www.nature.com/articles/s41586-023-06419-4#Equ1" target="_blank" rel="noopener noreferrer">1 ) 中所需的电机转速 Ω</a> <sub><font dir="auto">ss</font></sub> 。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="策略训练">策略训练<a href="#策略训练" class="hash-link" aria-label="策略训练的直接链接" title="策略训练的直接链接">​</a></h3>
<p>我们训练深度神经控制策略，将 平台状态和下一个门控观测值的观测值 <strong>o</strong> <sub><i><font dir="auto"><font dir="auto">t直接映射到质量归一化集体推力和身体速率</font></font></i></sub> [^44] 形式的控制动作 <strong>u</strong> <sub><i><font dir="auto"><font dir="auto">t</font></font></i></sub> 。控制策略在模拟中使用无模型强化学习进行训练。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="训练算法">训练算法<a href="#训练算法" class="hash-link" aria-label="训练算法的直接链接" title="训练算法的直接链接">​</a></h4>
<p><sup><a aria-label="参考文献 31" title="Schulman, J.、Wolski, F.、Dhariwal, P.、Radford, A. 和 Klimov, O. 近端策略优化算法。预印本链接：https://arxiv.org/abs/1707.06347 (2017)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR31"><font dir="auto"><font dir="auto">训练使用近端策略优化31</font></font></a></sup> 进行 。这种“演员-评论家”方法需要在训练期间联合优化两个神经网络：策略网络（将观察结果映射到动作）和价值网络（充当“评论家”并评估策略所采取的动作）。训练结束后，只需在机器人上部署策略网络。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="观察行动和奖励">观察、行动和奖励<a href="#观察行动和奖励" class="hash-link" aria-label="观察、行动和奖励的直接链接" title="观察、行动和奖励的直接链接">​</a></h4>
<p>$rt=rtprog+rtperc+rtcmd−rtcrash$</p>
<p>（7）</p>
<p>其中， <em>r</em> <sup><font dir="auto"><font dir="auto">prog</font></font></sup> 奖励朝着下一个门 [^35] 前进； <em>r</em> <sup><font dir="auto"><font dir="auto">perc</font></font></sup> 编码感知意识，通过调整车辆姿态使摄像头的光轴指向下一个门的中心； <em>r</em> <sup><font dir="auto"><font dir="auto">cmd</font></font></sup> 奖励平稳动作； <em>r</em> <sup><font dir="auto"><font dir="auto">crash</font></font></sup> 是一个二元惩罚，仅在与门碰撞或平台离开预定义边界框时生效。如果 <em>r</em> <sup><font dir="auto"><font dir="auto">crash</font></font></sup> 被触发，则训练过程结束。</p>
<p>具体来说，奖励条款如下</p>
<p>$rtprog=λ1[dt−1Gate−dtGate]rtperc=λ2exp⁡[λ3⋅δcam4]$</p>
<p>（8）</p>
<p>$rtcmd=λ4atω+λ5∥at−at−1∥2$</p>
<p>（9）</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="训练详情">训练详情<a href="#训练详情" class="hash-link" aria-label="训练详情的直接链接" title="训练详情的直接链接">​</a></h4>
<p>数据收集是通过模拟 100 个代理并行执行的，这些代理以 1,500 步为一集与环境交互。在每次环境重置时，每个代理都在轨道上的一个随机门处初始化，并在通过此门时围绕先前观察到的状态产生有界扰动。与以前的工作 44、49、50 不同 <sup><font dir="auto">，</font></sup> <sup><a aria-label="参考文献 50" title="Andrychowicz, OM 等人。学习灵巧的手持操作。《国际机器人研究杂志》39, 3–20 (2020)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR50"><font dir="auto">我们</font></a></sup> <sup><a aria-label="参考文献 49" title="莫尔查诺夫，A.等人。在过程中。 2019 年 IEEE/RSJ 国际智能机器人与系统会议 (IROS) 59–66（IEEE，2019）。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR49"><font dir="auto">在</font></a></sup> <sup><font dir="auto">训练</font></sup> <sup><a aria-label="参考文献 44" title="Kaufmann, E.、Bauersfeld, L. 和 Scaramuzza, D. 在 2022 年国际机器人与自动化会议 (ICRA) 10504–10510 (IEEE, 2022) 中。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR44"><font dir="auto"><font dir="auto">时</font></font></a></sup> 不对平台动态进行随机化。相反，我们根据真实数据进行微调。训练环境是使用 TensorFlow Agents [^51] 实现的。策略网络和价值网络均由两层感知器表示，每层有 128 个节点，LeakyReLU 激活具有负斜率为 0.2。使用 Adam 优化器优化网络参数， 策略网络和价值网络的学习率均为3 × 10 <sup><font dir="auto"><font dir="auto">−4 。</font></font></sup></p>
<p>策略训练总共涉及 1 × 10 <sup><font dir="auto"><font dir="auto">8 个</font></font></sup> 环境交互，在工作站（i9 12900K、RTX 3090、32 GB RAM DDR5）上耗时 50 分钟。微调涉及 2 × 10 <sup><font dir="auto"><font dir="auto">7 个</font></font></sup> 环境交互。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="残差模型辨识">残差模型辨识<a href="#残差模型辨识" class="hash-link" aria-label="残差模型辨识的直接链接" title="残差模型辨识的直接链接">​</a></h3>
<p>我们基于在现实世界中收集的少量数据对原始策略进行微调。具体来说，我们在现实世界中收集了三次完整的rollout数据，相当于大约50秒的飞行时间。我们通过识别残差观测值和残差动态来微调策略，并将其用于模拟训练。在此微调阶段，仅更新控制策略的权重，而门检测网络的权重保持不变。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="残差观测模型">残差观测模型<a href="#残差观测模型" class="hash-link" aria-label="残差观测模型的直接链接" title="残差观测模型的直接链接">​</a></h4>
<p>高速导航会导致严重的运动模糊，这可能导致追踪的视觉特征丢失，并导致线性里程计估计值出现严重漂移。我们使用一个里程计模型来微调策略，该模型仅从现实世界中记录的少量试验中识别出来。为了 对里程计中的漂移进行建模，我们使用高斯过程 [^36] ，因为它们可以拟合里程计扰动的后验分布，从而我们可以从中采样时间一致的实现。</p>
<p>具体来说，高斯过程模型将残差位置、速度和姿态拟合为机器人地面真实状态的函数。观测残差的识别是通过比较真实世界滚动过程中观察到的视觉惯性里程计 (VIO) 估计值与从外部运动跟踪系统获得的地面真实平台状态来实现的。</p>
<p>我们分别处理观测值的每个维度，有效地将一组九个一维高斯过程拟合到观测残差中。我们使用混合径向基函数核</p>
<p>$κ(zi,zj)=σf2exp⁡(−12(zi−zj)⊤L−2(zi−zj))+σn2$</p>
<p>（10）</p>
<p>其中 <em>L</em> 是对角长度尺度矩阵， <em>σ</em> <sub><font dir="auto"><font dir="auto">f</font></font></sub> 和 <em>σ</em> <sub><font dir="auto"><font dir="auto">n</font></font></sub> 分别表示数据和先验噪声方差， <strong>z</strong> <sub><i><font dir="auto"><font dir="auto">i</font></font></i></sub> 和 <strong>z</strong> <sub><i><font dir="auto"><font dir="auto">j</font></font></i></sub> 表示数据特征。通过最大化对数边际似然来优化核超参数。核超参数优化后，我们从后验分布中采样新的实现，然后用于策略的微调。扩展数据图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig5" target="_blank" rel="noopener noreferrer">1</a> 展示了实际部署中位置、速度和姿态的残差观测值，以及从高斯过程模型中采样的 100 个实现。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="残差动力学模型">残差动力学模型<a href="#残差动力学模型" class="hash-link" aria-label="残差动力学模型的直接链接" title="残差动力学模型的直接链接">​</a></h4>
<p>我们使用残差模型来补充模拟的机器人动力学 [^52] 。具体来说，我们将残差加速度确定为平台状态 <strong>s</strong> 和指令质量归一化总推力 <em>c</em> 的函数：</p>
<p>$ares=KNN(s,c)$</p>
<p>（11）</p>
<p>我们使用 <em>k = 5 的</em> <em>k</em> 最近邻回归。  用于残差动力学模型识别的数据集的大小取决于轨道布局，对于本研究中使用的轨道布局，范围在 800 到 1,000 个样本之间。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="门检测">门检测<a href="#门检测" class="hash-link" aria-label="门检测的直接链接" title="门检测的直接链接">​</a></h3>
<p>为了校正 VIO 管道累积的漂移，门被用作相对定位的不同地标。具体来说，通过分割门角 [^26] 在机载摄像头视图中检测门。英特尔实感追踪摄像头 T265 提供的灰度图像用作门检测器的输入图像。分割网络的架构是一个六级 U-Net [^53] ，每级有 (8, 16, 16, 16, 16) 个大小为 (3, 3, 3, 5, 7, 7) 的卷积滤波器，最后一个额外层对包含 12 个滤波器的 U-Net 的输出进行操作。使用 <em>α</em>  = 0.01 的 LeakyReLU 作为激活函数。为了在 NVIDIA Jetson TX2 上部署，该网络被移植到 TensorRT。为了优化内存占用和计算时间，推理以半精度模式（FP16）进行，图像在输入网络之前会被下采样至 384 × 384 的尺寸。在 NVIDIA Jetson TX2 上，一次前向传递需要 40 毫秒。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="vio漂移估计">VIO漂移估计<a href="#vio漂移估计" class="hash-link" aria-label="VIO漂移估计的直接链接" title="VIO漂移估计的直接链接">​</a></h3>
<p>来自 VIO 管道 <sup><a aria-label="参考文献 54" title="英特尔实感 T265 系列产品家族。https://www.intelrealsense.com/wp-content/uploads/2019/09/Intel_RealSense_Tracking_Camera_Datasheet_Rev004_release.pdf (2019)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR54"><font dir="auto"><font dir="auto">54 的</font></font></a></sup> 里程计估计值在高速飞行过程中会出现明显的漂移。我们使用门检测来稳定 VIO 产生的姿态估计值 。门检测器输出所有可见门的角点坐标。首先使用基于无穷小平面的姿态估计 (IPPE) [^34] 为所有预测门估计一个相对姿态。根据这个相对姿态估计值，将每个门观测值分配给已知轨迹布局中最近的门，从而得到无人机的姿态估计值。</p>
<p>状态 <strong>x</strong> 和协方差 <em>P</em> 更新由下式给出：</p>
<p>$xk+1=Fxk,Pk+1=FPkF⊤+Q,$</p>
<p>（12）</p>
<p>$F=[I3×3dtI3×303×3I3×3],Q=[σposI3×303×303×3σvelI3×3].$</p>
<p>（13）</p>
<p>$Kk=Pk−Hk⊤(HkPk−Hk⊤+R)−1,xk+=xk−+Kk(zk−H(xk−)),Pk+=(I−KkHk)Pk−,$</p>
<p>（14）</p>
<p>其中 <em>Kk</em> 是卡尔曼增益， <sup><i><font dir="auto"><font dir="auto">R</font></font></i></sup> <em>是</em> 测量协方差， <em>Hk</em> <sub><i><font dir="auto"><font dir="auto">是</font></font></i></sub> 测量矩阵。如果在单个摄像机帧中检测到多个门，则所有相对姿态估计都会被堆叠并在同一个卡尔曼滤波器更新步骤中处理。测量误差的主要来源是网络门角检测的不确定性。当应用 IPPE 时，图像平面中的这个误差会导致姿态误差。我们选择了一种基于采样的方法，从已知的平均门角检测不确定性中估计姿态误差。对于每个门，IPPE 算法应用于标称门观测以及 20 个扰动门角估计。然后使用所得的姿态估计分布来近似 门观测的测量协方差 <em>R。</em></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="模拟结果">模拟结果<a href="#模拟结果" class="hash-link" aria-label="模拟结果的直接链接" title="模拟结果的直接链接">​</a></h3>
<p>在自主无人机竞赛中要达到冠军级的表现需要克服两个挑战：不完善的感知和不完整的系统动态模型。在模拟的受控实验中，我们评估了我们的方法对这两个挑战的稳健性。为此，我们评估了在四种不同设置下部署时在竞赛任务中的表现。在设置 (1) 中，我们模拟了一个简单的四旋  翼模型，可以访问地面真实状态观测值。在设置 (2) 中，我们用从真实飞行中识别出的噪声观测值替换地面真实状态观测值。这些噪声观测值是通过从残差观测模型中采样一个实现生成的，并且与部署的控制器的感知意识无关。设置 (3) 和 (4) 分别与前两个设置共享观测模型，但用更精确的空气动力学模拟 [^43] 取代了简单的动力学模型。这四种设置允许对方法对动态变化和观测保真度的敏感性进行受控评估。</p>
<p>在这四种设置中，我们都根据以下基线对我们的方法进行基准测试：零样本、域随机化和时间最优。零样本基线表示使用无模型 RL 训练的基于学习的竞赛策略 [^35] ，该策略从训练域零样本部署到测试域。该策略的训练域等于实验设置 (1)，即理想化的动态和地面真实观测。域随机化通过随机化观测和动态属性来扩展零样本基线的学习策略，以提高鲁棒性。时间最优基线使用预先计算的时间最优轨迹 <sup><a aria-label="参考文献 28" title="Foehn, P.、Romero, A. 和 Scaramuzza, D. 四旋翼航点飞行的时间最优规划。《机器人科学》，第 6 卷，eabh1221 页（2021 年）。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR28"><font dir="auto"><font dir="auto">28 ，使用 MPC 控制器进行跟踪。与其他基于模型的时间最优飞行方法</font></font></a></sup> <sup><a aria-label="参考文献 55" title="Ryou, G.、Tal, E. 和 Karaman, S. 多保真度黑盒优化，实现时间最优的四旋翼飞行器机动。国际机器人研究杂志 40, 1352–1369 (2021)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR55"><font dir="auto"><font dir="auto">55、56</font></font></a> <a aria-label="参考文献 56" title="Pham, H. &amp; Pham, Q.-C. 一种基于可达性分析的时间最优路径参数化新方法。IEEE 机器人学报，34, 645–659 (2018)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR56"><font dir="auto"><font dir="auto">相比</font></font></a></sup> <sup><font dir="auto">，</font></sup> 此方法表现出最佳性能 。轨迹生成和 MPC 控制器使用的动态模型与实验设置 (1) 的模拟动态相匹配。</p>
<p>性能评估通过评估最快单圈时间、成功通过闸门的平均和最小观测距离以及成功完成的航迹百分比来体现。闸门距离指标衡量无人机通过闸门平面时与闸门上最近点之间的距离。闸门距离较大表示四旋翼飞行器通过时靠近闸门中心。较小的闸门距离可以提高速度，但也会增加碰撞或错过闸门的风险。任何导致碰撞的单圈均不视为有效。</p>
<p>结果总结在扩展数据表 <a href="https://www.nature.com/articles/s41586-023-06419-4#Tab1" target="_blank" rel="noopener noreferrer">1c</a> 中。所有方法在理想化的动态和地面实况观测中部署时都能成功完成任务，其中时间最优的基线产生最低的单圈时间。当部署在具有域转移的设置中时，无论是在动态还是观测中，所有基线的性能都会崩溃，并且三个基线都无法完成哪怕一圈。这种性能下降在基于学习的方法和传统方法中都有所表现。相比之下，我们的方法以动态和观测噪声的经验模型为特色，在所有部署设置中都取得了成功，单圈时间略有增加。</p>
<p>我们的方法之所以能够在各种部署机制中取得成功，关键在于它使用了基于真实数据估算的动态和观测噪声经验模型。将能够访问此类数据的方法与无法访问此类数据的方法进行比较并不完全公平。因此，我们还在访问与我们的方法相同的真实数据时，对所有基线方法的性能进行了基准测试。具体而言，我们比较了实验环境 (2) 下的性能，该环境采用理想化的动态模型，但感知存在噪声。所有基线方法都提供了我们用来表征观测噪声的相同高斯过程模型的预测值。 结果总结在扩展数据表 <a href="https://www.nature.com/articles/s41586-023-06419-4#Tab1" target="_blank" rel="noopener noreferrer">1b</a> 中。所有基线方法都受益于更真实的观测，从而获得了更高的完成率。然而，我们的方法是唯一能够可靠地完成整个轨迹的方法。除了观测噪声模型的预测之外，我们的方法还考虑了模型的不确定性。有关强化学习与最优控制在受控实验中的性能的深入比较，请参阅参考文献  [^57] 。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="经过多次迭代进行微调">经过多次迭代进行微调<a href="#经过多次迭代进行微调" class="hash-link" aria-label="经过多次迭代进行微调的直接链接" title="经过多次迭代进行微调的直接链接">​</a></h3>
<p>我们研究了迭代过程中行为变化的程度。分析结果表明，后续的微调操作对性能的提升和行为的改变几乎可以忽略不计（扩展数据图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig6" target="_blank" rel="noopener noreferrer">2</a> ）。</p>
<p>接下来，我们将提供有关此调查的更多细节。我们首先列举微调步骤，以提供必要的符号：</p>
<ol>
<li>在模拟中训练策略 0。</li>
<li>在现实世界中部署策略 0。该策略基于来自运动捕捉系统的真实数据运行。</li>
<li>识别现实世界中策略 0 观察到的残差。</li>
<li>通过对已识别的残差微调策略 0 来训练策略 1。</li>
<li>在现实世界中部署策略 1。该策略仅对机载传感测量数据起作用。</li>
<li>识别现实世界中策略 1 观察到的残差。</li>
<li>通过对已识别的残差进行策略 1 的微调来训练策略 2。</li>
</ol>
<p>我们在对各自的残差进行微调后，在模拟中比较了策略 1 和策略 2 的性能。结果如扩展数据图 <a href="https://www.nature.com/articles/s41586-023-06419-4#Fig6" target="_blank" rel="noopener noreferrer">2</a> 所示。我们观察到，与门中心的距离差异（该距离是衡量策略安全性的指标）为 0.09 ± 0.08 米。此外，完成一圈所需时间的差异为 0.02 ± 0.02 秒。请注意，这个单圈时间差异远远小于 Swift 和人类飞行员的单圈完成时间差异（0.16 秒）。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="无人机硬件配置">无人机硬件配置<a href="#无人机硬件配置" class="hash-link" aria-label="无人机硬件配置的直接链接" title="无人机硬件配置的直接链接">​</a></h3>
<p>人类飞行员和 Swift 使用的四旋翼飞行器具有相同的重量、形状和推进力。平台设计基于 Agilicious 框架 <sup><a aria-label="参考文献 58" title="Foehn, P. 等人。Agilicious：用于基于视觉飞行的开源和开放硬件敏捷四旋翼飞行器。《机器人科学》，7, eabl6259 (2022)。" href="https://www.nature.com/articles/s41586-023-06419-4#ref-CR58"><font dir="auto"><font dir="auto">58。</font></font></a></sup> 每辆车的重量为 870 克，可以产生大约 35 N 的最大静态推力，从而使静态推重比为 4.1。每个平台的底座由一个 Armattan Chameleon 6 英寸主机架组成，该主机架配备 T-Motor Velox 2306 电机和 5 英寸三叶螺旋桨。配备 Connect Tech Quasar 载板的 NVIDIA Jetson TX2 为自主无人机提供主要计算资源，具有运行速度为 2 GHz 的六核 CPU 和一个运行速度为 1.3 GHz 的具有 256 个 CUDA 核心的专用 GPU。虽然门检测网络的前向传递是在 GPU 上执行的，但竞赛策略是在 CPU 上评估的，一次推理传递需要 8 毫秒。自动无人机搭载英特尔 RealSense 追踪摄像头 T265，可提供 100 Hz 的 VIO 估计值 [^59] ，并通过 USB 传输至 NVIDIA Jetson TX2。载人无人机既不搭载 Jetson 计算机，也不搭载 RealSense 摄像头，而是配备了相应的压载物。由人类飞行员或 Swift 产生的总推力和机身速率等控制指令被发送到商用飞行控制器，该控制器基于 216 MHz 的 STM32 处理器运行。飞行控制器运行 Betaflight，这是一款开源飞行控制软件 [^45] 。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="人类飞行员的印象">人类飞行员的印象<a href="#人类飞行员的印象" class="hash-link" aria-label="人类飞行员的印象的直接链接" title="人类飞行员的印象的直接链接">​</a></h3>
<p>以下引言传达了与 Swift 比赛的三位人类冠军的印象。</p>
<p><strong>亚历克斯·瓦诺弗</strong> ：</p>
<ul>
<li>这些比赛将在 S 分段决出胜负，这是赛道上最具挑战性的部分。</li>
<li>这真是一场精彩的比赛！我离自主飞行的无人机太近了，以至于在努力跟上它的时候，我都能感觉到气流的冲击。</li>
</ul>
<p><strong>托马斯·比特马塔</strong> ：</p>
<ul>
<li>可能性无穷无尽，这是一个可能改变整个世界的开始。另一方面，我是个赛车手，我不希望任何东西比我更快。</li>
<li>随着飞行速度的加快，您需要牺牲精度来换取速度。</li>
<li>无人机的潜力令人振奋。很快，人工智能无人机甚至可以用作训练工具，帮助人们了解其未来的可能性。</li>
</ul>
<p><strong>马文·谢珀</strong> ：</p>
<ul>
<li>与机器比赛的感觉很不一样，因为你知道机器不会累。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="研究伦理">研究伦理<a href="#研究伦理" class="hash-link" aria-label="研究伦理的直接链接" title="研究伦理的直接链接">​</a></h3>
<p>本研究遵循《赫尔辛基宣言》进行。根据苏黎世大学的规章制度，由于未收集任何健康相关数据，本研究方案无需接受伦理委员会审查。受试者在参与研究前已签署书面知情同意书。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="数据可用性">数据可用性<a href="#数据可用性" class="hash-link" aria-label="数据可用性的直接链接" title="数据可用性的直接链接">​</a></h2>
<p>评估  本文结论所需的所有其他数据均包含在论文或扩展数据中。赛事的动作捕捉记录及其分析代码可在 Zenodo 的“racing_data.zip”文件中找到，网址为 <a href="https://doi.org/10.5281/zenodo.7955278" target="_blank" rel="noopener noreferrer">https://doi.org/10.5281/zenodo.7955278</a> 。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="代码可用性">代码可用性<a href="#代码可用性" class="hash-link" aria-label="代码可用性的直接链接" title="代码可用性的直接链接">​</a></h2>
<p>详细说明训练过程和算法的 Swift 伪代码可在 Zenodo 的“pseudocode.zip”文件中找到，网址为 <a href="https://doi.org/10.5281/zenodo.7955278" target="_blank" rel="noopener noreferrer">https://doi.org/10.5281/zenodo.7955278</a> 。为防止潜在的滥用，与本研究相关的完整源代码将不会公开。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="更多信息">更多信息<a href="#更多信息" class="hash-link" aria-label="更多信息的直接链接" title="更多信息的直接链接">​</a></h2>
<p>论文地址：<a href="https://www.nature.com/articles/s41586-023-06419-4" target="_blank" rel="noopener noreferrer">https://www.nature.com/articles/s41586-023-06419-4</a></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-tags-row"><div class="col"><b>标签：</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/tags/clippings">clippings</a></li></ul></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/06_RL"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">9.6 强化学习</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Algorithm_Development/RL/DifferentiablePhysicsDrone/通过可微分物理学习基于视觉 的敏捷飞行"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">通过可微分物理学习基于视觉的敏捷飞行</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#摘要" class="table-of-contents__link toc-highlight">摘要</a></li><li><a href="#主要的" class="table-of-contents__link toc-highlight">主要的</a></li><li><a href="#swift-系统" class="table-of-contents__link toc-highlight">Swift 系统</a></li><li><a href="#结果" class="table-of-contents__link toc-highlight">结果</a></li><li><a href="#讨论" class="table-of-contents__link toc-highlight">讨论</a></li><li><a href="#方法" class="table-of-contents__link toc-highlight">方法</a><ul><li><a href="#四旋翼飞行器模拟" class="table-of-contents__link toc-highlight">四旋翼飞行器模拟</a></li><li><a href="#策略训练" class="table-of-contents__link toc-highlight">策略训练</a></li><li><a href="#残差模型辨识" class="table-of-contents__link toc-highlight">残差模型辨识</a></li><li><a href="#门检测" class="table-of-contents__link toc-highlight">门检测</a></li><li><a href="#vio漂移估计" class="table-of-contents__link toc-highlight">VIO漂移估计</a></li><li><a href="#模拟结果" class="table-of-contents__link toc-highlight">模拟结果</a></li><li><a href="#经过多次迭代进行微调" class="table-of-contents__link toc-highlight">经过多次迭代进行微调</a></li><li><a href="#无人机硬件配置" class="table-of-contents__link toc-highlight">无人机硬件配置</a></li><li><a href="#人类飞行员的印象" class="table-of-contents__link toc-highlight">人类飞行员的印象</a></li><li><a href="#研究伦理" class="table-of-contents__link toc-highlight">研究伦理</a></li></ul></li><li><a href="#数据可用性" class="table-of-contents__link toc-highlight">数据可用性</a></li><li><a href="# 代码可用性" class="table-of-contents__link toc-highlight">代码可用性</a></li><li><a href="#更多信息" class="table-of-contents__link toc-highlight">更多信息</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Links</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.utmsys.org/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Homepage<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.utmsys.org/pages/contact/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Contact Us<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Follow Us</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/utmsys" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.youtube.com/@utmsys/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Youtube<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.facebook.com/profile.php?id=61574010301135/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Facebook<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://www.instagram.com/utmsys/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Instagram<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 UTMSYS.</div></div></div></footer></div>
</body>
</html>